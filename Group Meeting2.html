<!DOCTYPE html><html lang="en-US"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,height=device-height,initial-scale=1.0"><meta name="apple-mobile-web-app-capable" content="yes"><meta http-equiv="X-UA-Compatible" content="ie=edge"><meta property="og:type" content="website"><meta name="twitter:card" content="summary"><style>@media screen{body[data-bespoke-view=""] .bespoke-marp-parent>.bespoke-marp-osc>button,body[data-bespoke-view=next] .bespoke-marp-parent>.bespoke-marp-osc>button,body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-info-container button,body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-note-container button{-webkit-tap-highlight-color:transparent;-webkit-appearance:none;appearance:none;background-color:initial;border:0;color:inherit;cursor:pointer;font-size:inherit;opacity:.8;outline:none;padding:0;transition:opacity .2s linear}body[data-bespoke-view=""] .bespoke-marp-parent>.bespoke-marp-osc>button:disabled,body[data-bespoke-view=next] .bespoke-marp-parent>.bespoke-marp-osc>button:disabled,body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-info-container button:disabled,body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-note-container button:disabled{cursor:not-allowed;opacity:.15!important}body[data-bespoke-view=""] .bespoke-marp-parent>.bespoke-marp-osc>button:hover,body[data-bespoke-view=next] .bespoke-marp-parent>.bespoke-marp-osc>button:hover,body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-info-container button:hover,body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-note-container button:hover{opacity:1}body[data-bespoke-view=""] .bespoke-marp-parent>.bespoke-marp-osc>button:hover:active,body[data-bespoke-view=next] .bespoke-marp-parent>.bespoke-marp-osc>button:hover:active,body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-info-container button:hover:active,body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-note-container button:hover:active{opacity:.6}body[data-bespoke-view=""] .bespoke-marp-parent>.bespoke-marp-osc>button:hover:not(:disabled),body[data-bespoke-view=next] .bespoke-marp-parent>.bespoke-marp-osc>button:hover:not(:disabled),body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-info-container button:hover:not(:disabled),body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-note-container button:hover:not(:disabled){transition:none}body[data-bespoke-view=""] .bespoke-marp-parent>.bespoke-marp-osc>button[data-bespoke-marp-osc=prev],body[data-bespoke-view=next] .bespoke-marp-parent>.bespoke-marp-osc>button[data-bespoke-marp-osc=prev],body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-info-container button.bespoke-marp-presenter-info-page-prev{background:#0000 url("data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAxMDAgMTAwIj48cGF0aCBmaWxsPSJub25lIiBzdHJva2U9IiNmZmYiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCIgc3Ryb2tlLWxpbmVqb2luPSJyb3VuZCIgc3Ryb2tlLXdpZHRoPSI1IiBkPSJNNjggOTAgMjggNTBsNDAtNDAiLz48L3N2Zz4=") no-repeat 50%;background-size:contain;overflow:hidden;text-indent:100%;white-space:nowrap}body[data-bespoke-view=""] .bespoke-marp-parent>.bespoke-marp-osc>button[data-bespoke-marp-osc=next],body[data-bespoke-view=next] .bespoke-marp-parent>.bespoke-marp-osc>button[data-bespoke-marp-osc=next],body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-info-container button.bespoke-marp-presenter-info-page-next{background:#0000 url("data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAxMDAgMTAwIj48cGF0aCBmaWxsPSJub25lIiBzdHJva2U9IiNmZmYiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCIgc3Ryb2tlLWxpbmVqb2luPSJyb3VuZCIgc3Ryb2tlLXdpZHRoPSI1IiBkPSJtMzIgOTAgNDAtNDAtNDAtNDAiLz48L3N2Zz4=") no-repeat 50%;background-size:contain;overflow:hidden;text-indent:100%;white-space:nowrap}body[data-bespoke-view=""] .bespoke-marp-parent>.bespoke-marp-osc>button[data-bespoke-marp-osc=fullscreen],body[data-bespoke-view=next] .bespoke-marp-parent>.bespoke-marp-osc>button[data-bespoke-marp-osc=fullscreen]{background:#0000 url("data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAxMDAgMTAwIj48ZGVmcz48c3R5bGU+LmF7ZmlsbDpub25lO3N0cm9rZTojZmZmO3N0cm9rZS1saW5lY2FwOnJvdW5kO3N0cm9rZS1saW5lam9pbjpyb3VuZDtzdHJva2Utd2lkdGg6NXB4fTwvc3R5bGU+PC9kZWZzPjxyZWN0IHdpZHRoPSI4MCIgaGVpZ2h0PSI2MCIgeD0iMTAiIHk9IjIwIiBjbGFzcz0iYSIgcng9IjUuNjciLz48cGF0aCBkPSJNNDAgNzBIMjBWNTBtMjAgMEwyMCA3MG00MC00MGgyMHYyMG0tMjAgMCAyMC0yMCIgY2xhc3M9ImEiLz48L3N2Zz4=") no-repeat 50%;background-size:contain;overflow:hidden;text-indent:100%;white-space:nowrap}body[data-bespoke-view=""] .bespoke-marp-parent>.bespoke-marp-osc>button.exit[data-bespoke-marp-osc=fullscreen],body[data-bespoke-view=next] .bespoke-marp-parent>.bespoke-marp-osc>button.exit[data-bespoke-marp-osc=fullscreen]{background-image:url("data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAxMDAgMTAwIj48ZGVmcz48c3R5bGU+LmF7ZmlsbDpub25lO3N0cm9rZTojZmZmO3N0cm9rZS1saW5lY2FwOnJvdW5kO3N0cm9rZS1saW5lam9pbjpyb3VuZDtzdHJva2Utd2lkdGg6NXB4fTwvc3R5bGU+PC9kZWZzPjxyZWN0IHdpZHRoPSI4MCIgaGVpZ2h0PSI2MCIgeD0iMTAiIHk9IjIwIiBjbGFzcz0iYSIgcng9IjUuNjciLz48cGF0aCBkPSJNMjAgNTBoMjB2MjBtLTIwIDAgMjAtMjBtNDAgMEg2MFYzMG0yMCAwTDYwIDUwIiBjbGFzcz0iYSIvPjwvc3ZnPg==")}body[data-bespoke-view=""] .bespoke-marp-parent>.bespoke-marp-osc>button[data-bespoke-marp-osc=presenter],body[data-bespoke-view=next] .bespoke-marp-parent>.bespoke-marp-osc>button[data-bespoke-marp-osc=presenter]{background:#0000 url("data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAxMDAgMTAwIj48cGF0aCBmaWxsPSJub25lIiBzdHJva2U9IiNmZmYiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCIgc3Ryb2tlLWxpbmVqb2luPSJyb3VuZCIgc3Ryb2tlLXdpZHRoPSI1IiBkPSJNODcuOCA0Ny41Qzg5IDUwIDg3LjcgNTIgODUgNTJIMzVhOC43IDguNyAwIDAgMS03LjItNC41bC0xNS42LTMxQzExIDE0IDEyLjIgMTIgMTUgMTJoNTBhOC44IDguOCAwIDAgMSA3LjIgNC41ek02MCA1MnYzNm0tMTAgMGgyME00NSA0MmgyMCIvPjwvc3ZnPg==") no-repeat 50%;background-size:contain;overflow:hidden;text-indent:100%;white-space:nowrap}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-note-container button.bespoke-marp-presenter-note-bigger{background:#0000 url("data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAxMDAgMTAwIj48cGF0aCBzdHJva2U9IiNmZmYiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCIgc3Ryb2tlLWxpbmVqb2luPSJyb3VuZCIgc3Ryb2tlLXdpZHRoPSI1IiBkPSJNMTIgNTBoODBNNTIgOTBWMTAiLz48L3N2Zz4=") no-repeat 50%;background-size:contain;overflow:hidden;text-indent:100%;white-space:nowrap}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-note-container button.bespoke-marp-presenter-note-smaller{background:#0000 url("data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAxMDAgMTAwIj48cGF0aCBmaWxsPSJub25lIiBzdHJva2U9IiNmZmYiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCIgc3Ryb2tlLWxpbmVqb2luPSJyb3VuZCIgc3Ryb2tlLXdpZHRoPSI1IiBkPSJNMTIgNTBoODAiLz48L3N2Zz4=") no-repeat 50%;background-size:contain;overflow:hidden;text-indent:100%;white-space:nowrap}}@keyframes __bespoke_marp_transition_reduced_outgoing__{0%{opacity:1}to{opacity:0}}@keyframes __bespoke_marp_transition_reduced_incoming__{0%{mix-blend-mode:plus-lighter;opacity:0}to{mix-blend-mode:plus-lighter;opacity:1}}.bespoke-marp-note,.bespoke-marp-osc,.bespoke-progress-parent{display:none;transition:none}@media screen{::view-transition-group(*){animation-duration:var(--marp-bespoke-transition-animation-duration,.5s);animation-timing-function:ease}::view-transition-new(*),::view-transition-old(*){animation-delay:0s;animation-direction:var(--marp-bespoke-transition-animation-direction,normal);animation-duration:var(--marp-bespoke-transition-animation-duration,.5s);animation-fill-mode:both;animation-name:var(--marp-bespoke-transition-animation-name,var(--marp-bespoke-transition-animation-name-fallback,__bespoke_marp_transition_no_animation__));mix-blend-mode:normal}::view-transition-old(*){--marp-bespoke-transition-animation-name-fallback:__bespoke_marp_transition_reduced_outgoing__;animation-timing-function:ease}::view-transition-new(*){--marp-bespoke-transition-animation-name-fallback:__bespoke_marp_transition_reduced_incoming__;animation-timing-function:ease}::view-transition-new(root),::view-transition-old(root){animation-timing-function:linear}::view-transition-new(__bespoke_marp_transition_osc__),::view-transition-old(__bespoke_marp_transition_osc__){animation-duration:0s!important;animation-name:__bespoke_marp_transition_osc__!important}::view-transition-new(__bespoke_marp_transition_osc__){opacity:0!important}.bespoke-marp-transition-warming-up::view-transition-group(*),.bespoke-marp-transition-warming-up::view-transition-new(*),.bespoke-marp-transition-warming-up::view-transition-old(*){animation-play-state:paused!important}body,html{height:100%;margin:0}body{background:#000;overflow:hidden}svg.bespoke-marp-slide{content-visibility:hidden;opacity:0;pointer-events:none;z-index:-1}svg.bespoke-marp-slide:not(.bespoke-marp-active) *{view-transition-name:none!important}svg.bespoke-marp-slide.bespoke-marp-active{content-visibility:visible;opacity:1;pointer-events:auto;z-index:0}svg.bespoke-marp-slide.bespoke-marp-active.bespoke-marp-active-ready *{animation-name:__bespoke_marp__!important}@supports not (content-visibility:hidden){svg.bespoke-marp-slide[data-bespoke-marp-load=hideable]{display:none}svg.bespoke-marp-slide[data-bespoke-marp-load=hideable].bespoke-marp-active{display:block}}}@media screen and (prefers-reduced-motion:reduce){svg.bespoke-marp-slide *{view-transition-name:none!important}}@media screen{[data-bespoke-marp-fragment=inactive]{visibility:hidden}body[data-bespoke-view=""] .bespoke-marp-parent,body[data-bespoke-view=next] .bespoke-marp-parent{inset:0;position:absolute}body[data-bespoke-view=""] .bespoke-marp-parent>.bespoke-marp-osc,body[data-bespoke-view=next] .bespoke-marp-parent>.bespoke-marp-osc{view-transition-name:__bespoke_marp_transition_osc__;background:#000000a6;border-radius:7px;bottom:50px;color:#fff;contain:paint;display:block;font-family:Helvetica,Arial,sans-serif;font-size:16px;left:50%;line-height:0;opacity:1;padding:12px;position:absolute;touch-action:manipulation;transform:translateX(-50%);transition:opacity .2s linear;-webkit-user-select:none;user-select:none;white-space:nowrap;will-change:transform;z-index:1}body[data-bespoke-view=""] .bespoke-marp-parent>.bespoke-marp-osc>*,body[data-bespoke-view=next] .bespoke-marp-parent>.bespoke-marp-osc>*{margin-left:6px}body[data-bespoke-view=""] .bespoke-marp-parent>.bespoke-marp-osc>:first-child,body[data-bespoke-view=next] .bespoke-marp-parent>.bespoke-marp-osc>:first-child{margin-left:0}body[data-bespoke-view=""] .bespoke-marp-parent>.bespoke-marp-osc>span,body[data-bespoke-view=next] .bespoke-marp-parent>.bespoke-marp-osc>span{opacity:.8}body[data-bespoke-view=""] .bespoke-marp-parent>.bespoke-marp-osc>span[data-bespoke-marp-osc=page],body[data-bespoke-view=next] .bespoke-marp-parent>.bespoke-marp-osc>span[data-bespoke-marp-osc=page]{display:inline-block;min-width:140px;text-align:center}body[data-bespoke-view=""] .bespoke-marp-parent>.bespoke-marp-osc>button[data-bespoke-marp-osc=fullscreen],body[data-bespoke-view=""] .bespoke-marp-parent>.bespoke-marp-osc>button[data-bespoke-marp-osc=next],body[data-bespoke-view=""] .bespoke-marp-parent>.bespoke-marp-osc>button[data-bespoke-marp-osc=presenter],body[data-bespoke-view=""] .bespoke-marp-parent>.bespoke-marp-osc>button[data-bespoke-marp-osc=prev],body[data-bespoke-view=next] .bespoke-marp-parent>.bespoke-marp-osc>button[data-bespoke-marp-osc=fullscreen],body[data-bespoke-view=next] .bespoke-marp-parent>.bespoke-marp-osc>button[data-bespoke-marp-osc=next],body[data-bespoke-view=next] .bespoke-marp-parent>.bespoke-marp-osc>button[data-bespoke-marp-osc=presenter],body[data-bespoke-view=next] .bespoke-marp-parent>.bespoke-marp-osc>button[data-bespoke-marp-osc=prev]{height:32px;line-height:32px;width:32px}body[data-bespoke-view=""] .bespoke-marp-parent.bespoke-marp-inactive,body[data-bespoke-view=next] .bespoke-marp-parent.bespoke-marp-inactive{cursor:none}body[data-bespoke-view=""] .bespoke-marp-parent.bespoke-marp-inactive>.bespoke-marp-osc,body[data-bespoke-view=next] .bespoke-marp-parent.bespoke-marp-inactive>.bespoke-marp-osc{opacity:0;pointer-events:none}body[data-bespoke-view=""] svg.bespoke-marp-slide,body[data-bespoke-view=next] svg.bespoke-marp-slide{height:100%;left:0;position:absolute;top:0;width:100%}body[data-bespoke-view=""] .bespoke-progress-parent{background:#222;display:flex;height:5px;width:100%}body[data-bespoke-view=""] .bespoke-progress-parent+.bespoke-marp-parent{top:5px}body[data-bespoke-view=""] .bespoke-progress-parent .bespoke-progress-bar{background:#0288d1;flex:0 0 0;transition:flex-basis .2s cubic-bezier(0,1,1,1)}body[data-bespoke-view=next]{background:#0000}body[data-bespoke-view=presenter]{background:#161616}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container{display:grid;font-family:Helvetica,Arial,sans-serif;grid-template:"current dragbar next" minmax(140px,1fr) "current dragbar note" 2fr "info    dragbar note" 3em;grid-template-columns:minmax(3px,var(--bespoke-marp-presenter-split-ratio,66%)) 0 minmax(3px,1fr);height:100%;left:0;position:absolute;top:0;width:100%}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-parent{grid-area:current;overflow:hidden;position:relative}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-parent svg.bespoke-marp-slide{height:calc(100% - 40px);left:20px;pointer-events:none;position:absolute;top:20px;-webkit-user-select:none;user-select:none;width:calc(100% - 40px)}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-parent svg.bespoke-marp-slide.bespoke-marp-active{filter:drop-shadow(0 3px 10px rgba(0,0,0,.5))}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-dragbar-container{background:#0288d1;cursor:col-resize;grid-area:dragbar;margin-left:-3px;opacity:0;position:relative;transition:opacity .4s linear .1s;width:6px;z-index:10}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-dragbar-container:hover{opacity:1}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-dragbar-container.active{opacity:1;transition-delay:0s}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-next-container{background:#222;cursor:pointer;display:none;grid-area:next;overflow:hidden;position:relative}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-next-container.active{display:block}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-next-container iframe.bespoke-marp-presenter-next{background:#0000;border:0;display:block;filter:drop-shadow(0 3px 10px rgba(0,0,0,.5));height:calc(100% - 40px);left:20px;pointer-events:none;position:absolute;top:20px;-webkit-user-select:none;user-select:none;width:calc(100% - 40px)}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-note-container{background:#222;color:#eee;grid-area:note;position:relative;z-index:1}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-note-container button{height:1.5em;line-height:1.5em;width:1.5em}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-note-container .bespoke-marp-presenter-note-wrapper{display:block;inset:0;position:absolute}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-note-container .bespoke-marp-presenter-note-buttons{background:#000000a6;border-radius:4px;bottom:0;display:flex;gap:4px;margin:12px;opacity:0;padding:6px;pointer-events:none;position:absolute;right:0;transition:opacity .2s linear}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-note-container .bespoke-marp-presenter-note-buttons:focus-within,body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-note-container .bespoke-marp-presenter-note-wrapper:focus-within+.bespoke-marp-presenter-note-buttons,body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-note-container:hover .bespoke-marp-presenter-note-buttons{opacity:1;pointer-events:auto}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-note-container .bespoke-marp-note{word-wrap:break-word;box-sizing:border-box;font-size:calc(1.1em*var(--bespoke-marp-note-font-scale, 1));height:calc(100% - 40px);margin:20px;overflow:auto;padding-right:3px;scrollbar-color:#eeeeee80 #0000;scrollbar-width:thin;white-space:pre-wrap;width:calc(100% - 40px)}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-note-container .bespoke-marp-note::-webkit-scrollbar{width:6px}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-note-container .bespoke-marp-note::-webkit-scrollbar-track{background:#0000}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-note-container .bespoke-marp-note::-webkit-scrollbar-thumb{background:#eeeeee80;border-radius:6px}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-note-container .bespoke-marp-note:empty{pointer-events:none}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-note-container .bespoke-marp-note.active{display:block}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-note-container .bespoke-marp-note p:first-child{margin-top:0}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-note-container .bespoke-marp-note p:last-child{margin-bottom:0}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-info-container{align-items:center;box-sizing:border-box;color:#eee;display:flex;flex-wrap:nowrap;grid-area:info;justify-content:center;overflow:hidden;padding:0 10px}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-info-container .bespoke-marp-presenter-info-page,body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-info-container .bespoke-marp-presenter-info-time,body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-info-container .bespoke-marp-presenter-info-timer{box-sizing:border-box;display:block;padding:0 10px;white-space:nowrap;width:100%}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-info-container button{height:1.5em;line-height:1.5em;width:1.5em}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-info-container .bespoke-marp-presenter-info-page{order:2;text-align:center}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-info-container .bespoke-marp-presenter-info-page .bespoke-marp-presenter-info-page-text{display:inline-block;min-width:120px;text-align:center}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-info-container .bespoke-marp-presenter-info-time{color:#999;order:1;text-align:left}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-info-container .bespoke-marp-presenter-info-timer{color:#999;order:3;text-align:right}body[data-bespoke-view=presenter] .bespoke-marp-presenter-container .bespoke-marp-presenter-info-container .bespoke-marp-presenter-info-timer:hover{cursor:pointer}}@media print{.bespoke-marp-presenter-info-container,.bespoke-marp-presenter-next-container,.bespoke-marp-presenter-note-container{display:none}}</style><style>div#\:\$p>svg>foreignObject>section{width:1280px;height:720px;box-sizing:border-box;overflow:hidden;position:relative;scroll-snap-align:center center}div#\:\$p>svg>foreignObject>section:after{bottom:0;content:attr(data-marpit-pagination);padding:inherit;pointer-events:none;position:absolute;right:0}div#\:\$p>svg>foreignObject>section:not([data-marpit-pagination]):after{display:none}/* Normalization */div#\:\$p>svg>foreignObject>section :is(h1,marp-h1){font-size:2em;margin:0.67em 0}div#\:\$p>svg>foreignObject>section video::-webkit-media-controls{will-change:transform}@page{size:1280px 720px;margin:0}@media print{body,html{background-color:#fff;margin:0;page-break-inside:avoid;break-inside:avoid-page}div#\:\$p>svg>foreignObject>section{page-break-before:always;break-before:page}div#\:\$p>svg>foreignObject>section,div#\:\$p>svg>foreignObject>section *{-webkit-print-color-adjust:exact!important;animation-delay:0s!important;animation-duration:0s!important;color-adjust:exact!important;transition:none!important}div#\:\$p>svg[data-marpit-svg]{display:block;height:100vh;width:100vw}}div#\:\$p>svg>foreignObject>section img[data-marp-twemoji]{background:transparent;height:1em;margin:0 .05em 0 .1em;vertical-align:-.1em;width:1em}
/*!
 * Marp default theme.
 *
 * @theme default
 * @author Yuki Hattori
 *
 * @auto-scaling true
 * @size 16:9 1280px 720px
 * @size 4:3 960px 720px
 */div#\:\$p>svg>foreignObject>section{--color-prettylights-syntax-comment:#6e7781;--color-prettylights-syntax-constant:#0550ae;--color-prettylights-syntax-entity:#8250df;--color-prettylights-syntax-storage-modifier-import:#24292f;--color-prettylights-syntax-entity-tag:#116329;--color-prettylights-syntax-keyword:#cf222e;--color-prettylights-syntax-string:#0a3069;--color-prettylights-syntax-variable:#953800;--color-prettylights-syntax-brackethighlighter-unmatched:#82071e;--color-prettylights-syntax-invalid-illegal-text:#f6f8fa;--color-prettylights-syntax-invalid-illegal-bg:#82071e;--color-prettylights-syntax-carriage-return-text:#f6f8fa;--color-prettylights-syntax-carriage-return-bg:#cf222e;--color-prettylights-syntax-string-regexp:#116329;--color-prettylights-syntax-markup-list:#3b2300;--color-prettylights-syntax-markup-heading:#0550ae;--color-prettylights-syntax-markup-italic:#24292f;--color-prettylights-syntax-markup-bold:#24292f;--color-prettylights-syntax-markup-deleted-text:#82071e;--color-prettylights-syntax-markup-deleted-bg:#ffebe9;--color-prettylights-syntax-markup-inserted-text:#116329;--color-prettylights-syntax-markup-inserted-bg:#dafbe1;--color-prettylights-syntax-markup-changed-text:#953800;--color-prettylights-syntax-markup-changed-bg:#ffd8b5;--color-prettylights-syntax-markup-ignored-text:#eaeef2;--color-prettylights-syntax-markup-ignored-bg:#0550ae;--color-prettylights-syntax-meta-diff-range:#8250df;--color-prettylights-syntax-brackethighlighter-angle:#57606a;--color-prettylights-syntax-sublimelinter-gutter-mark:#8c959f;--color-prettylights-syntax-constant-other-reference-link:#0a3069;--color-fg-default:#24292f;--color-fg-muted:#57606a;--color-fg-subtle:#6e7781;--color-canvas-default:#fff;--color-canvas-subtle:#f6f8fa;--color-border-default:#d0d7de;--color-border-muted:#d8dee4;--color-neutral-muted:rgba(175,184,193,.2);--color-accent-fg:#0969da;--color-accent-emphasis:#0969da;--color-attention-subtle:#fff8c5;--color-danger-fg:#cf222e;color-scheme:light}div#\:\$p>svg>foreignObject>section:where(.invert){--color-prettylights-syntax-comment:#8b949e;--color-prettylights-syntax-constant:#79c0ff;--color-prettylights-syntax-entity:#d2a8ff;--color-prettylights-syntax-storage-modifier-import:#c9d1d9;--color-prettylights-syntax-entity-tag:#7ee787;--color-prettylights-syntax-keyword:#ff7b72;--color-prettylights-syntax-string:#a5d6ff;--color-prettylights-syntax-variable:#ffa657;--color-prettylights-syntax-brackethighlighter-unmatched:#f85149;--color-prettylights-syntax-invalid-illegal-text:#f0f6fc;--color-prettylights-syntax-invalid-illegal-bg:#8e1519;--color-prettylights-syntax-carriage-return-text:#f0f6fc;--color-prettylights-syntax-carriage-return-bg:#b62324;--color-prettylights-syntax-string-regexp:#7ee787;--color-prettylights-syntax-markup-list:#f2cc60;--color-prettylights-syntax-markup-heading:#1f6feb;--color-prettylights-syntax-markup-italic:#c9d1d9;--color-prettylights-syntax-markup-bold:#c9d1d9;--color-prettylights-syntax-markup-deleted-text:#ffdcd7;--color-prettylights-syntax-markup-deleted-bg:#67060c;--color-prettylights-syntax-markup-inserted-text:#aff5b4;--color-prettylights-syntax-markup-inserted-bg:#033a16;--color-prettylights-syntax-markup-changed-text:#ffdfb6;--color-prettylights-syntax-markup-changed-bg:#5a1e02;--color-prettylights-syntax-markup-ignored-text:#c9d1d9;--color-prettylights-syntax-markup-ignored-bg:#1158c7;--color-prettylights-syntax-meta-diff-range:#d2a8ff;--color-prettylights-syntax-brackethighlighter-angle:#8b949e;--color-prettylights-syntax-sublimelinter-gutter-mark:#484f58;--color-prettylights-syntax-constant-other-reference-link:#a5d6ff;--color-fg-default:#c9d1d9;--color-fg-muted:#8b949e;--color-fg-subtle:#6e7681;--color-canvas-default:#0d1117;--color-canvas-subtle:#161b22;--color-border-default:#30363d;--color-border-muted:#21262d;--color-neutral-muted:hsla(215,8%,47%,.4);--color-accent-fg:#58a6ff;--color-accent-emphasis:#1f6feb;--color-attention-subtle:rgba(187,128,9,.15);--color-danger-fg:#f85149;color-scheme:dark}div#\:\$p>svg>foreignObject>section{-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%;word-wrap:break-word;background-color:var(--color-canvas-default);color:var(--color-fg-default);font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Noto Sans,Helvetica,Arial,sans-serif,Apple Color Emoji,Segoe UI Emoji;font-size:16px;line-height:1.5;margin:0}div#\:\$p>svg>foreignObject>section{--marpit-root-font-size:16px}div#\:\$p>svg>foreignObject>section :is(h1,marp-h1):hover .anchor .octicon-link:before,div#\:\$p>svg>foreignObject>section :is(h2,marp-h2):hover .anchor .octicon-link:before,div#\:\$p>svg>foreignObject>section :is(h3,marp-h3):hover .anchor .octicon-link:before,div#\:\$p>svg>foreignObject>section :is(h4,marp-h4):hover .anchor .octicon-link:before,div#\:\$p>svg>foreignObject>section :is(h5,marp-h5):hover .anchor .octicon-link:before,div#\:\$p>svg>foreignObject>section :is(h6,marp-h6):hover .anchor .octicon-link:before{background-color:currentColor;content:" ";display:inline-block;height:16px;-webkit-mask-image:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 0 0 1.06 1.06l1.25-1.25a2 2 0 1 1 2.83 2.83l-2.5 2.5a2 2 0 0 1-2.83 0 .75.75 0 0 0-1.06 1.06 3.5 3.5 0 0 0 4.95 0l2.5-2.5a3.5 3.5 0 0 0-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 0 1 0-2.83l2.5-2.5a2 2 0 0 1 2.83 0 .75.75 0 0 0 1.06-1.06 3.5 3.5 0 0 0-4.95 0l-2.5 2.5a3.5 3.5 0 0 0 4.95 4.95l1.25-1.25a.75.75 0 0 0-1.06-1.06l-1.25 1.25a2 2 0 0 1-2.83 0z"/></svg>');mask-image:url('data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 0 0 1.06 1.06l1.25-1.25a2 2 0 1 1 2.83 2.83l-2.5 2.5a2 2 0 0 1-2.83 0 .75.75 0 0 0-1.06 1.06 3.5 3.5 0 0 0 4.95 0l2.5-2.5a3.5 3.5 0 0 0-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 0 1 0-2.83l2.5-2.5a2 2 0 0 1 2.83 0 .75.75 0 0 0 1.06-1.06 3.5 3.5 0 0 0-4.95 0l-2.5 2.5a3.5 3.5 0 0 0 4.95 4.95l1.25-1.25a.75.75 0 0 0-1.06-1.06l-1.25 1.25a2 2 0 0 1-2.83 0z"/></svg>');width:16px}div#\:\$p>svg>foreignObject>section details,div#\:\$p>svg>foreignObject>section figcaption,div#\:\$p>svg>foreignObject>section figure{display:block}div#\:\$p>svg>foreignObject>section summary{display:list-item}div#\:\$p>svg>foreignObject>section [hidden]{display:none!important}div#\:\$p>svg>foreignObject>section a{background-color:transparent;color:var(--color-accent-fg);text-decoration:none}div#\:\$p>svg>foreignObject>section abbr[title]{border-bottom:none;-webkit-text-decoration:underline dotted;text-decoration:underline dotted}div#\:\$p>svg>foreignObject>section b,div#\:\$p>svg>foreignObject>section strong{font-weight:var(--base-text-weight-semibold,600)}div#\:\$p>svg>foreignObject>section dfn{font-style:italic}div#\:\$p>svg>foreignObject>section :is(h1,marp-h1){border-bottom:1px solid var(--color-border-muted);font-size:2em;font-weight:var(--base-text-weight-semibold,600);margin:.67em 0;padding-bottom:.3em}div#\:\$p>svg>foreignObject>section mark{background-color:var(--color-attention-subtle);color:var(--color-fg-default)}div#\:\$p>svg>foreignObject>section small{font-size:90%}div#\:\$p>svg>foreignObject>section sub,div#\:\$p>svg>foreignObject>section sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}div#\:\$p>svg>foreignObject>section sub{bottom:-.25em}div#\:\$p>svg>foreignObject>section sup{top:-.5em}div#\:\$p>svg>foreignObject>section img{background-color:var(--color-canvas-default);border-style:none;box-sizing:content-box;max-width:100%}div#\:\$p>svg>foreignObject>section :is(pre,marp-pre),div#\:\$p>svg>foreignObject>section code,div#\:\$p>svg>foreignObject>section kbd,div#\:\$p>svg>foreignObject>section samp{font-family:monospace;font-size:1em}div#\:\$p>svg>foreignObject>section figure{margin:1em 40px}div#\:\$p>svg>foreignObject>section hr{background:transparent;background-color:var(--color-border-default);border:0;box-sizing:content-box;height:.25em;margin:24px 0;overflow:hidden;padding:0}div#\:\$p>svg>foreignObject>section input{font:inherit;font-family:inherit;font-size:inherit;line-height:inherit;margin:0;overflow:visible}div#\:\$p>svg>foreignObject>section [type=button],div#\:\$p>svg>foreignObject>section [type=reset],div#\:\$p>svg>foreignObject>section [type=submit]{-webkit-appearance:button}div#\:\$p>svg>foreignObject>section [type=checkbox],div#\:\$p>svg>foreignObject>section [type=radio]{box-sizing:border-box;padding:0}div#\:\$p>svg>foreignObject>section [type=number]::-webkit-inner-spin-button,div#\:\$p>svg>foreignObject>section [type=number]::-webkit-outer-spin-button{height:auto}div#\:\$p>svg>foreignObject>section [type=search]::-webkit-search-cancel-button,div#\:\$p>svg>foreignObject>section [type=search]::-webkit-search-decoration{-webkit-appearance:none}div#\:\$p>svg>foreignObject>section ::-webkit-input-placeholder{color:inherit;opacity:.54}div#\:\$p>svg>foreignObject>section ::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}div#\:\$p>svg>foreignObject>section a:hover{text-decoration:underline}div#\:\$p>svg>foreignObject>section ::-moz-placeholder{color:var(--color-fg-subtle);opacity:1}div#\:\$p>svg>foreignObject>section ::placeholder{color:var(--color-fg-subtle);opacity:1}div#\:\$p>svg>foreignObject>section hr:after,div#\:\$p>svg>foreignObject>section hr:before{content:"";display:table}div#\:\$p>svg>foreignObject>section hr:after{clear:both}div#\:\$p>svg>foreignObject>section table{border-collapse:collapse;border-spacing:0;display:block;max-width:100%;overflow:auto;width:-moz-max-content;width:max-content}div#\:\$p>svg>foreignObject>section td,div#\:\$p>svg>foreignObject>section th{padding:0}div#\:\$p>svg>foreignObject>section details summary{cursor:pointer}div#\:\$p>svg>foreignObject>section details:not([open])>:not(summary){display:none!important}div#\:\$p>svg>foreignObject>section [role=button]:focus,div#\:\$p>svg>foreignObject>section a:focus,div#\:\$p>svg>foreignObject>section input[type=checkbox]:focus,div#\:\$p>svg>foreignObject>section input[type=radio]:focus{box-shadow:none;outline:2px solid var(--color-accent-fg);outline-offset:-2px}div#\:\$p>svg>foreignObject>section [role=button]:focus:not(:focus-visible),div#\:\$p>svg>foreignObject>section a:focus:not(:focus-visible),div#\:\$p>svg>foreignObject>section input[type=checkbox]:focus:not(:focus-visible),div#\:\$p>svg>foreignObject>section input[type=radio]:focus:not(:focus-visible){outline:1px solid transparent}div#\:\$p>svg>foreignObject>section [role=button]:focus-visible,div#\:\$p>svg>foreignObject>section a:focus-visible,div#\:\$p>svg>foreignObject>section input[type=checkbox]:focus-visible,div#\:\$p>svg>foreignObject>section input[type=radio]:focus-visible{box-shadow:none;outline:2px solid var(--color-accent-fg);outline-offset:-2px}div#\:\$p>svg>foreignObject>section a:not([class]):focus,div#\:\$p>svg>foreignObject>section a:not([class]):focus-visible,div#\:\$p>svg>foreignObject>section input[type=checkbox]:focus,div#\:\$p>svg>foreignObject>section input[type=checkbox]:focus-visible,div#\:\$p>svg>foreignObject>section input[type=radio]:focus,div#\:\$p>svg>foreignObject>section input[type=radio]:focus-visible{outline-offset:0}div#\:\$p>svg>foreignObject>section kbd{background-color:var(--color-canvas-subtle);border-bottom-color:var(--color-neutral-muted);border:1px solid var(--color-neutral-muted);border-radius:6px;box-shadow:inset 0 -1px 0 var(--color-neutral-muted);color:var(--color-fg-default);display:inline-block;font:11px ui-monospace,SFMono-Regular,SF Mono,Menlo,Consolas,Liberation Mono,monospace;line-height:10px;padding:3px 5px;vertical-align:middle}div#\:\$p>svg>foreignObject>section :is(h1,marp-h1),div#\:\$p>svg>foreignObject>section :is(h2,marp-h2),div#\:\$p>svg>foreignObject>section :is(h3,marp-h3),div#\:\$p>svg>foreignObject>section :is(h4,marp-h4),div#\:\$p>svg>foreignObject>section :is(h5,marp-h5),div#\:\$p>svg>foreignObject>section :is(h6,marp-h6){font-weight:var(--base-text-weight-semibold,600);line-height:1.25;margin-bottom:16px;margin-top:24px}div#\:\$p>svg>foreignObject>section :is(h2,marp-h2){border-bottom:1px solid var(--color-border-muted);font-size:1.5em;padding-bottom:.3em}div#\:\$p>svg>foreignObject>section :is(h2,marp-h2),div#\:\$p>svg>foreignObject>section :is(h3,marp-h3){font-weight:var(--base-text-weight-semibold,600)}div#\:\$p>svg>foreignObject>section :is(h3,marp-h3){font-size:1.25em}div#\:\$p>svg>foreignObject>section :is(h4,marp-h4){font-size:1em}div#\:\$p>svg>foreignObject>section :is(h4,marp-h4),div#\:\$p>svg>foreignObject>section :is(h5,marp-h5){font-weight:var(--base-text-weight-semibold,600)}div#\:\$p>svg>foreignObject>section :is(h5,marp-h5){font-size:.875em}div#\:\$p>svg>foreignObject>section :is(h6,marp-h6){color:var(--color-fg-muted);font-size:.85em;font-weight:var(--base-text-weight-semibold,600)}div#\:\$p>svg>foreignObject>section p{margin-bottom:10px;margin-top:0}div#\:\$p>svg>foreignObject>section blockquote{border-left:.25em solid var(--color-border-default);color:var(--color-fg-muted);margin:0;padding:0 1em}div#\:\$p>svg>foreignObject>section ol,div#\:\$p>svg>foreignObject>section ul{margin-bottom:0;margin-top:0;padding-left:2em}div#\:\$p>svg>foreignObject>section ol ol,div#\:\$p>svg>foreignObject>section ul ol{list-style-type:lower-roman}div#\:\$p>svg>foreignObject>section ol ol ol,div#\:\$p>svg>foreignObject>section ol ul ol,div#\:\$p>svg>foreignObject>section ul ol ol,div#\:\$p>svg>foreignObject>section ul ul ol{list-style-type:lower-alpha}div#\:\$p>svg>foreignObject>section dd{margin-left:0}div#\:\$p>svg>foreignObject>section :is(pre,marp-pre),div#\:\$p>svg>foreignObject>section code,div#\:\$p>svg>foreignObject>section samp,div#\:\$p>svg>foreignObject>section tt{font-family:ui-monospace,SFMono-Regular,SF Mono,Menlo,Consolas,Liberation Mono,monospace;font-size:12px}div#\:\$p>svg>foreignObject>section :is(pre,marp-pre){word-wrap:normal;margin-bottom:0;margin-top:0}div#\:\$p>svg>foreignObject>section .octicon{fill:currentColor;display:inline-block;overflow:visible!important;vertical-align:text-bottom}div#\:\$p>svg>foreignObject>section input::-webkit-inner-spin-button,div#\:\$p>svg>foreignObject>section input::-webkit-outer-spin-button{-webkit-appearance:none;appearance:none;margin:0}div#\:\$p>svg>foreignObject>section:after,div#\:\$p>svg>foreignObject>section:before{
  /* content:""; */display:table}div#\:\$p>svg>foreignObject>section:after{clear:both}div#\:\$p>svg>foreignObject>section>:first-child{margin-top:0!important}div#\:\$p>svg>foreignObject>section>:last-child{margin-bottom:0!important}div#\:\$p>svg>foreignObject>section a:not([href]){color:inherit;text-decoration:none}div#\:\$p>svg>foreignObject>section .absent{color:var(--color-danger-fg)}div#\:\$p>svg>foreignObject>section .anchor{float:left;line-height:1;margin-left:-20px;padding-right:4px}div#\:\$p>svg>foreignObject>section .anchor:focus{outline:none}div#\:\$p>svg>foreignObject>section :is(pre,marp-pre),div#\:\$p>svg>foreignObject>section blockquote,div#\:\$p>svg>foreignObject>section details,div#\:\$p>svg>foreignObject>section dl,div#\:\$p>svg>foreignObject>section ol,div#\:\$p>svg>foreignObject>section p,div#\:\$p>svg>foreignObject>section table,div#\:\$p>svg>foreignObject>section ul{margin-bottom:16px;margin-top:0}div#\:\$p>svg>foreignObject>section blockquote>:first-child{margin-top:0}div#\:\$p>svg>foreignObject>section blockquote>:last-child{margin-bottom:0}div#\:\$p>svg>foreignObject>section :is(h1,marp-h1) .octicon-link,div#\:\$p>svg>foreignObject>section :is(h2,marp-h2) .octicon-link,div#\:\$p>svg>foreignObject>section :is(h3,marp-h3) .octicon-link,div#\:\$p>svg>foreignObject>section :is(h4,marp-h4) .octicon-link,div#\:\$p>svg>foreignObject>section :is(h5,marp-h5) .octicon-link,div#\:\$p>svg>foreignObject>section :is(h6,marp-h6) .octicon-link{color:var(--color-fg-default);vertical-align:middle;visibility:hidden}div#\:\$p>svg>foreignObject>section :is(h1,marp-h1):hover .anchor,div#\:\$p>svg>foreignObject>section :is(h2,marp-h2):hover .anchor,div#\:\$p>svg>foreignObject>section :is(h3,marp-h3):hover .anchor,div#\:\$p>svg>foreignObject>section :is(h4,marp-h4):hover .anchor,div#\:\$p>svg>foreignObject>section :is(h5,marp-h5):hover .anchor,div#\:\$p>svg>foreignObject>section :is(h6,marp-h6):hover .anchor{text-decoration:none}div#\:\$p>svg>foreignObject>section :is(h1,marp-h1):hover .anchor .octicon-link,div#\:\$p>svg>foreignObject>section :is(h2,marp-h2):hover .anchor .octicon-link,div#\:\$p>svg>foreignObject>section :is(h3,marp-h3):hover .anchor .octicon-link,div#\:\$p>svg>foreignObject>section :is(h4,marp-h4):hover .anchor .octicon-link,div#\:\$p>svg>foreignObject>section :is(h5,marp-h5):hover .anchor .octicon-link,div#\:\$p>svg>foreignObject>section :is(h6,marp-h6):hover .anchor .octicon-link{visibility:visible}div#\:\$p>svg>foreignObject>section :is(h1,marp-h1) code,div#\:\$p>svg>foreignObject>section :is(h1,marp-h1) tt,div#\:\$p>svg>foreignObject>section :is(h2,marp-h2) code,div#\:\$p>svg>foreignObject>section :is(h2,marp-h2) tt,div#\:\$p>svg>foreignObject>section :is(h3,marp-h3) code,div#\:\$p>svg>foreignObject>section :is(h3,marp-h3) tt,div#\:\$p>svg>foreignObject>section :is(h4,marp-h4) code,div#\:\$p>svg>foreignObject>section :is(h4,marp-h4) tt,div#\:\$p>svg>foreignObject>section :is(h5,marp-h5) code,div#\:\$p>svg>foreignObject>section :is(h5,marp-h5) tt,div#\:\$p>svg>foreignObject>section :is(h6,marp-h6) code,div#\:\$p>svg>foreignObject>section :is(h6,marp-h6) tt{font-size:inherit;padding:0 .2em}div#\:\$p>svg>foreignObject>section summary :is(h1,marp-h1),div#\:\$p>svg>foreignObject>section summary :is(h2,marp-h2),div#\:\$p>svg>foreignObject>section summary :is(h3,marp-h3),div#\:\$p>svg>foreignObject>section summary :is(h4,marp-h4),div#\:\$p>svg>foreignObject>section summary :is(h5,marp-h5),div#\:\$p>svg>foreignObject>section summary :is(h6,marp-h6){display:inline-block}div#\:\$p>svg>foreignObject>section summary :is(h1,marp-h1) .anchor,div#\:\$p>svg>foreignObject>section summary :is(h2,marp-h2) .anchor,div#\:\$p>svg>foreignObject>section summary :is(h3,marp-h3) .anchor,div#\:\$p>svg>foreignObject>section summary :is(h4,marp-h4) .anchor,div#\:\$p>svg>foreignObject>section summary :is(h5,marp-h5) .anchor,div#\:\$p>svg>foreignObject>section summary :is(h6,marp-h6) .anchor{margin-left:-40px}div#\:\$p>svg>foreignObject>section summary :is(h1,marp-h1),div#\:\$p>svg>foreignObject>section summary :is(h2,marp-h2){border-bottom:0;padding-bottom:0}div#\:\$p>svg>foreignObject>section ol.no-list,div#\:\$p>svg>foreignObject>section ul.no-list{list-style-type:none;padding:0}div#\:\$p>svg>foreignObject>section ol[type=a]{list-style-type:lower-alpha}div#\:\$p>svg>foreignObject>section ol[type=A]{list-style-type:upper-alpha}div#\:\$p>svg>foreignObject>section ol[type=i]{list-style-type:lower-roman}div#\:\$p>svg>foreignObject>section ol[type=I]{list-style-type:upper-roman}div#\:\$p>svg>foreignObject>section div>ol:not([type]),div#\:\$p>svg>foreignObject>section ol[type="1"]{list-style-type:decimal}div#\:\$p>svg>foreignObject>section ol ol,div#\:\$p>svg>foreignObject>section ol ul,div#\:\$p>svg>foreignObject>section ul ol,div#\:\$p>svg>foreignObject>section ul ul{margin-bottom:0;margin-top:0}div#\:\$p>svg>foreignObject>section li>p{margin-top:16px}div#\:\$p>svg>foreignObject>section li+li{margin-top:.25em}div#\:\$p>svg>foreignObject>section dl{padding:0}div#\:\$p>svg>foreignObject>section dl dt{font-size:1em;font-style:italic;font-weight:var(--base-text-weight-semibold,600);margin-top:16px;padding:0}div#\:\$p>svg>foreignObject>section dl dd{margin-bottom:16px;padding:0 16px}div#\:\$p>svg>foreignObject>section table th{font-weight:var(--base-text-weight-semibold,600)}div#\:\$p>svg>foreignObject>section table td,div#\:\$p>svg>foreignObject>section table th{border:1px solid var(--color-border-default);padding:6px 13px}div#\:\$p>svg>foreignObject>section table tr{background-color:var(--color-canvas-default);border-top:1px solid var(--color-border-muted)}div#\:\$p>svg>foreignObject>section table tr:nth-child(2n){background-color:var(--color-canvas-subtle)}div#\:\$p>svg>foreignObject>section table img{background-color:transparent}div#\:\$p>svg>foreignObject>section img[align=right]{padding-left:20px}div#\:\$p>svg>foreignObject>section img[align=left]{padding-right:20px}div#\:\$p>svg>foreignObject>section .emoji{background-color:transparent;max-width:none;vertical-align:text-top}div#\:\$p>svg>foreignObject>section :is(span,marp-span).frame,div#\:\$p>svg>foreignObject>section :is(span,marp-span).frame>:is(span,marp-span){display:block;overflow:hidden}div#\:\$p>svg>foreignObject>section :is(span,marp-span).frame>:is(span,marp-span){border:1px solid var(--color-border-default);float:left;margin:13px 0 0;padding:7px;width:auto}div#\:\$p>svg>foreignObject>section :is(span,marp-span).frame :is(span,marp-span) img{display:block;float:left}div#\:\$p>svg>foreignObject>section :is(span,marp-span).frame :is(span,marp-span) :is(span,marp-span){clear:both;color:var(--color-fg-default);display:block;padding:5px 0 0}div#\:\$p>svg>foreignObject>section :is(span,marp-span).align-center{clear:both;display:block;overflow:hidden}div#\:\$p>svg>foreignObject>section :is(span,marp-span).align-center>:is(span,marp-span){display:block;margin:13px auto 0;overflow:hidden;text-align:center}div#\:\$p>svg>foreignObject>section :is(span,marp-span).align-center :is(span,marp-span) img{margin:0 auto;text-align:center}div#\:\$p>svg>foreignObject>section :is(span,marp-span).align-right{clear:both;display:block;overflow:hidden}div#\:\$p>svg>foreignObject>section :is(span,marp-span).align-right>:is(span,marp-span){display:block;margin:13px 0 0;overflow:hidden;text-align:right}div#\:\$p>svg>foreignObject>section :is(span,marp-span).align-right :is(span,marp-span) img{margin:0;text-align:right}div#\:\$p>svg>foreignObject>section :is(span,marp-span).float-left{display:block;float:left;margin-right:13px;overflow:hidden}div#\:\$p>svg>foreignObject>section :is(span,marp-span).float-left :is(span,marp-span){margin:13px 0 0}div#\:\$p>svg>foreignObject>section :is(span,marp-span).float-right{display:block;float:right;margin-left:13px;overflow:hidden}div#\:\$p>svg>foreignObject>section :is(span,marp-span).float-right>:is(span,marp-span){display:block;margin:13px auto 0;overflow:hidden;text-align:right}div#\:\$p>svg>foreignObject>section code,div#\:\$p>svg>foreignObject>section tt{background-color:var(--color-neutral-muted);border-radius:6px;font-size:85%;margin:0;padding:.2em .4em;white-space:break-spaces}div#\:\$p>svg>foreignObject>section code br,div#\:\$p>svg>foreignObject>section tt br{display:none}div#\:\$p>svg>foreignObject>section del code{text-decoration:inherit}div#\:\$p>svg>foreignObject>section samp{font-size:85%}div#\:\$p>svg>foreignObject>section :is(pre,marp-pre) code{font-size:100%}div#\:\$p>svg>foreignObject>section :is(pre,marp-pre)>code{background:transparent;border:0;margin:0;padding:0;white-space:pre;word-break:normal}div#\:\$p>svg>foreignObject>section .highlight{margin-bottom:16px}div#\:\$p>svg>foreignObject>section .highlight :is(pre,marp-pre){margin-bottom:0;word-break:normal}div#\:\$p>svg>foreignObject>section :is(pre,marp-pre){background-color:var(--color-canvas-subtle);border-radius:6px;font-size:85%;line-height:1.45;overflow:auto;padding:16px}div#\:\$p>svg>foreignObject>section :is(pre,marp-pre) code,div#\:\$p>svg>foreignObject>section :is(pre,marp-pre) tt{word-wrap:normal;background-color:transparent;border:0;display:inline;line-height:inherit;margin:0;max-width:auto;overflow:visible;padding:0}div#\:\$p>svg>foreignObject>section .csv-data td,div#\:\$p>svg>foreignObject>section .csv-data th{font-size:12px;line-height:1;overflow:hidden;padding:5px;text-align:left;white-space:nowrap}div#\:\$p>svg>foreignObject>section .csv-data .blob-num{background:var(--color-canvas-default);border:0;padding:10px 8px 9px;text-align:right}div#\:\$p>svg>foreignObject>section .csv-data tr{border-top:0}div#\:\$p>svg>foreignObject>section .csv-data th{background:var(--color-canvas-subtle);border-top:0;font-weight:var(--base-text-weight-semibold,600)}div#\:\$p>svg>foreignObject>section [data-footnote-ref]:before{content:"["}div#\:\$p>svg>foreignObject>section [data-footnote-ref]:after{content:"]"}div#\:\$p>svg>foreignObject>section .footnotes{border-top:1px solid var(--color-border-default);color:var(--color-fg-muted);font-size:12px}div#\:\$p>svg>foreignObject>section div#\:\$p>svg>foreignObject>section section.footnotes{--marpit-root-font-size:12px}div#\:\$p>svg>foreignObject>section .footnotes ol{padding-left:16px}div#\:\$p>svg>foreignObject>section .footnotes ol ul{display:inline-block;margin-top:16px;padding-left:16px}div#\:\$p>svg>foreignObject>section .footnotes li{position:relative}div#\:\$p>svg>foreignObject>section .footnotes li:target:before{border:2px solid var(--color-accent-emphasis);border-radius:6px;bottom:-8px;content:"";left:-24px;pointer-events:none;position:absolute;right:-8px;top:-8px}div#\:\$p>svg>foreignObject>section .footnotes li:target{color:var(--color-fg-default)}div#\:\$p>svg>foreignObject>section .footnotes .data-footnote-backref g-emoji{font-family:monospace}div#\:\$p>svg>foreignObject>section .pl-c{color:var(--color-prettylights-syntax-comment)}div#\:\$p>svg>foreignObject>section .pl-c1,div#\:\$p>svg>foreignObject>section .pl-s .pl-v{color:var(--color-prettylights-syntax-constant)}div#\:\$p>svg>foreignObject>section .pl-e,div#\:\$p>svg>foreignObject>section .pl-en{color:var(--color-prettylights-syntax-entity)}div#\:\$p>svg>foreignObject>section .pl-s .pl-s1,div#\:\$p>svg>foreignObject>section .pl-smi{color:var(--color-prettylights-syntax-storage-modifier-import)}div#\:\$p>svg>foreignObject>section .pl-ent{color:var(--color-prettylights-syntax-entity-tag)}div#\:\$p>svg>foreignObject>section .pl-k{color:var(--color-prettylights-syntax-keyword)}div#\:\$p>svg>foreignObject>section .pl-pds,div#\:\$p>svg>foreignObject>section .pl-s,div#\:\$p>svg>foreignObject>section .pl-s .pl-pse .pl-s1,div#\:\$p>svg>foreignObject>section .pl-sr,div#\:\$p>svg>foreignObject>section .pl-sr .pl-cce,div#\:\$p>svg>foreignObject>section .pl-sr .pl-sra,div#\:\$p>svg>foreignObject>section .pl-sr .pl-sre{color:var(--color-prettylights-syntax-string)}div#\:\$p>svg>foreignObject>section .pl-smw,div#\:\$p>svg>foreignObject>section .pl-v{color:var(--color-prettylights-syntax-variable)}div#\:\$p>svg>foreignObject>section .pl-bu{color:var(--color-prettylights-syntax-brackethighlighter-unmatched)}div#\:\$p>svg>foreignObject>section .pl-ii{background-color:var(--color-prettylights-syntax-invalid-illegal-bg);color:var(--color-prettylights-syntax-invalid-illegal-text)}div#\:\$p>svg>foreignObject>section .pl-c2{background-color:var(--color-prettylights-syntax-carriage-return-bg);color:var(--color-prettylights-syntax-carriage-return-text)}div#\:\$p>svg>foreignObject>section .pl-sr .pl-cce{color:var(--color-prettylights-syntax-string-regexp);font-weight:700}div#\:\$p>svg>foreignObject>section .pl-ml{color:var(--color-prettylights-syntax-markup-list)}div#\:\$p>svg>foreignObject>section .pl-mh,div#\:\$p>svg>foreignObject>section .pl-mh .pl-en,div#\:\$p>svg>foreignObject>section .pl-ms{color:var(--color-prettylights-syntax-markup-heading);font-weight:700}div#\:\$p>svg>foreignObject>section .pl-mi{color:var(--color-prettylights-syntax-markup-italic);font-style:italic}div#\:\$p>svg>foreignObject>section .pl-mb{color:var(--color-prettylights-syntax-markup-bold);font-weight:700}div#\:\$p>svg>foreignObject>section .pl-md{background-color:var(--color-prettylights-syntax-markup-deleted-bg);color:var(--color-prettylights-syntax-markup-deleted-text)}div#\:\$p>svg>foreignObject>section .pl-mi1{background-color:var(--color-prettylights-syntax-markup-inserted-bg);color:var(--color-prettylights-syntax-markup-inserted-text)}div#\:\$p>svg>foreignObject>section .pl-mc{background-color:var(--color-prettylights-syntax-markup-changed-bg);color:var(--color-prettylights-syntax-markup-changed-text)}div#\:\$p>svg>foreignObject>section .pl-mi2{background-color:var(--color-prettylights-syntax-markup-ignored-bg);color:var(--color-prettylights-syntax-markup-ignored-text)}div#\:\$p>svg>foreignObject>section .pl-mdr{color:var(--color-prettylights-syntax-meta-diff-range);font-weight:700}div#\:\$p>svg>foreignObject>section .pl-ba{color:var(--color-prettylights-syntax-brackethighlighter-angle)}div#\:\$p>svg>foreignObject>section .pl-sg{color:var(--color-prettylights-syntax-sublimelinter-gutter-mark)}div#\:\$p>svg>foreignObject>section .pl-corl{color:var(--color-prettylights-syntax-constant-other-reference-link);text-decoration:underline}div#\:\$p>svg>foreignObject>section g-emoji{display:inline-block;font-family:Apple Color Emoji,Segoe UI Emoji,Segoe UI Symbol;font-size:1em;font-style:normal!important;font-weight:var(--base-text-weight-normal,400);line-height:1;min-width:1ch;vertical-align:-.075em}div#\:\$p>svg>foreignObject>section g-emoji img{height:1em;width:1em}div#\:\$p>svg>foreignObject>section .task-list-item{list-style-type:none}div#\:\$p>svg>foreignObject>section .task-list-item label{font-weight:var(--base-text-weight-normal,400)}div#\:\$p>svg>foreignObject>section .task-list-item.enabled label{cursor:pointer}div#\:\$p>svg>foreignObject>section .task-list-item+.task-list-item{margin-top:4px}div#\:\$p>svg>foreignObject>section .task-list-item .handle{display:none}div#\:\$p>svg>foreignObject>section .task-list-item-checkbox{margin:0 .2em .25em -1.4em;vertical-align:middle}div#\:\$p>svg>foreignObject>section .contains-task-list:dir(rtl) .task-list-item-checkbox{margin:0 -1.6em .25em .2em}div#\:\$p>svg>foreignObject>section .contains-task-list{position:relative}div#\:\$p>svg>foreignObject>section .contains-task-list:focus-within .task-list-item-convert-container,div#\:\$p>svg>foreignObject>section .contains-task-list:hover .task-list-item-convert-container{clip:auto;display:block;height:24px;overflow:visible;width:auto}div#\:\$p>svg>foreignObject>section ::-webkit-calendar-picker-indicator{filter:invert(50%)}div#\:\$p>svg>foreignObject>section :is(h1,marp-h1){color:var(--h1-color);font-size:1.6em}div#\:\$p>svg>foreignObject>section :is(h1,marp-h1),div#\:\$p>svg>foreignObject>section :is(h2,marp-h2){border-bottom:none}div#\:\$p>svg>foreignObject>section :is(h2,marp-h2){font-size:1.3em}div#\:\$p>svg>foreignObject>section :is(h3,marp-h3){font-size:1.1em}div#\:\$p>svg>foreignObject>section :is(h4,marp-h4){font-size:1.05em}div#\:\$p>svg>foreignObject>section :is(h5,marp-h5){font-size:1em}div#\:\$p>svg>foreignObject>section :is(h6,marp-h6){font-size:.9em}div#\:\$p>svg>foreignObject>section :is(h1,marp-h1) strong,div#\:\$p>svg>foreignObject>section :is(h2,marp-h2) strong,div#\:\$p>svg>foreignObject>section :is(h3,marp-h3) strong,div#\:\$p>svg>foreignObject>section :is(h4,marp-h4) strong,div#\:\$p>svg>foreignObject>section :is(h5,marp-h5) strong,div#\:\$p>svg>foreignObject>section :is(h6,marp-h6) strong{color:var(--heading-strong-color);font-weight:inherit}div#\:\$p>svg>foreignObject>section :is(h1,marp-h1)::part(auto-scaling),div#\:\$p>svg>foreignObject>section :is(h2,marp-h2)::part(auto-scaling),div#\:\$p>svg>foreignObject>section :is(h3,marp-h3)::part(auto-scaling),div#\:\$p>svg>foreignObject>section :is(h4,marp-h4)::part(auto-scaling),div#\:\$p>svg>foreignObject>section :is(h5,marp-h5)::part(auto-scaling),div#\:\$p>svg>foreignObject>section :is(h6,marp-h6)::part(auto-scaling){max-height:563px}div#\:\$p>svg>foreignObject>section hr{height:0;padding-top:.25em}div#\:\$p>svg>foreignObject>section :is(pre,marp-pre){border:1px solid var(--color-border-default);line-height:1.15;overflow:visible}div#\:\$p>svg>foreignObject>section :is(pre,marp-pre)::part(auto-scaling){max-height:529px}div#\:\$p>svg>foreignObject>section :is(pre,marp-pre) :where(.hljs){color:var(--color-prettylights-syntax-storage-modifier-import)}div#\:\$p>svg>foreignObject>section :is(pre,marp-pre) :where(.hljs-doctag),div#\:\$p>svg>foreignObject>section :is(pre,marp-pre) :where(.hljs-keyword),div#\:\$p>svg>foreignObject>section :is(pre,marp-pre) :where(.hljs-meta .hljs-keyword),div#\:\$p>svg>foreignObject>section :is(pre,marp-pre) :where(.hljs-template-tag),div#\:\$p>svg>foreignObject>section :is(pre,marp-pre) :where(.hljs-template-variable),div#\:\$p>svg>foreignObject>section :is(pre,marp-pre) :where(.hljs-type),div#\:\$p>svg>foreignObject>section :is(pre,marp-pre) :where(.hljs-variable.language_){color:var(--color-prettylights-syntax-keyword)}div#\:\$p>svg>foreignObject>section :is(pre,marp-pre) :where(.hljs-title),div#\:\$p>svg>foreignObject>section :is(pre,marp-pre) :where(.hljs-title.class_),div#\:\$p>svg>foreignObject>section :is(pre,marp-pre) :where(.hljs-title.class_.inherited__),div#\:\$p>svg>foreignObject>section :is(pre,marp-pre) :where(.hljs-title.function_){color:var(--color-prettylights-syntax-entity)}div#\:\$p>svg>foreignObject>section :is(pre,marp-pre) :where(.hljs-attr),div#\:\$p>svg>foreignObject>section :is(pre,marp-pre) :where(.hljs-attribute),div#\:\$p>svg>foreignObject>section :is(pre,marp-pre) :where(.hljs-literal),div#\:\$p>svg>foreignObject>section :is(pre,marp-pre) :where(.hljs-meta),div#\:\$p>svg>foreignObject>section :is(pre,marp-pre) :where(.hljs-number),div#\:\$p>svg>foreignObject>section :is(pre,marp-pre) :where(.hljs-operator),div#\:\$p>svg>foreignObject>section :is(pre,marp-pre) :where(.hljs-selector-attr),div#\:\$p>svg>foreignObject>section :is(pre,marp-pre) :where(.hljs-selector-class),div#\:\$p>svg>foreignObject>section :is(pre,marp-pre) :where(.hljs-selector-id),div#\:\$p>svg>foreignObject>section :is(pre,marp-pre) :where(.hljs-variable){color:var(--color-prettylights-syntax-constant)}div#\:\$p>svg>foreignObject>section :is(pre,marp-pre) :where(.hljs-meta .hljs-string),div#\:\$p>svg>foreignObject>section :is(pre,marp-pre) :where(.hljs-regexp),div#\:\$p>svg>foreignObject>section :is(pre,marp-pre) :where(.hljs-string){color:var(--color-prettylights-syntax-string)}div#\:\$p>svg>foreignObject>section :is(pre,marp-pre) :where(.hljs-built_in),div#\:\$p>svg>foreignObject>section :is(pre,marp-pre) :where(.hljs-symbol){color:var(--color-prettylights-syntax-variable)}div#\:\$p>svg>foreignObject>section :is(pre,marp-pre) :where(.hljs-code),div#\:\$p>svg>foreignObject>section :is(pre,marp-pre) :where(.hljs-comment),div#\:\$p>svg>foreignObject>section :is(pre,marp-pre) :where(.hljs-formula){color:var(--color-prettylights-syntax-comment)}div#\:\$p>svg>foreignObject>section :is(pre,marp-pre) :where(.hljs-name),div#\:\$p>svg>foreignObject>section :is(pre,marp-pre) :where(.hljs-quote),div#\:\$p>svg>foreignObject>section :is(pre,marp-pre) :where(.hljs-selector-pseudo),div#\:\$p>svg>foreignObject>section :is(pre,marp-pre) :where(.hljs-selector-tag){color:var(--color-prettylights-syntax-entity-tag)}div#\:\$p>svg>foreignObject>section :is(pre,marp-pre) :where(.hljs-subst){color:var(--color-prettylights-syntax-storage-modifier-import)}div#\:\$p>svg>foreignObject>section :is(pre,marp-pre) :where(.hljs-section){color:var(--color-prettylights-syntax-markup-heading);font-weight:700}div#\:\$p>svg>foreignObject>section :is(pre,marp-pre) :where(.hljs-bullet){color:var(--color-prettylights-syntax-markup-list)}div#\:\$p>svg>foreignObject>section :is(pre,marp-pre) :where(.hljs-emphasis){color:var(--color-prettylights-syntax-markup-italic);font-style:italic}div#\:\$p>svg>foreignObject>section :is(pre,marp-pre) :where(.hljs-strong){color:var(--color-prettylights-syntax-markup-bold);font-weight:700}div#\:\$p>svg>foreignObject>section :is(pre,marp-pre) :where(.hljs-addition){background-color:var(--color-prettylights-syntax-markup-inserted-bg);color:var(--color-prettylights-syntax-markup-inserted-text)}div#\:\$p>svg>foreignObject>section :is(pre,marp-pre) :where(.hljs-deletion){background-color:var(--color-prettylights-syntax-markup-deleted-bg);color:var(--color-prettylights-syntax-markup-deleted-text)}div#\:\$p>svg>foreignObject>section footer,div#\:\$p>svg>foreignObject>section header{color:var(--header-footer-color);font-size:18px;left:30px;margin:0;position:absolute}div#\:\$p>svg>foreignObject>section header{top:21px}div#\:\$p>svg>foreignObject>section footer{bottom:21px}div#\:\$p>svg>foreignObject>section{--h1-color:#246;--header-footer-color:hsla(0,0%,40%,.75);--heading-strong-color:#48c;--paginate-color:#777;align-items:stretch;display:flex;flex-flow:column nowrap;font-size:29px;height:720px;justify-content:center;padding:78.5px;width:1280px}div#\:\$p>svg>foreignObject>section{--marpit-root-font-size:29px}div#\:\$p>svg>foreignObject>section:where(.invert){--h1-color:#cee7ff;--header-footer-color:hsla(0,0%,60%,.75);--heading-strong-color:#7bf;--paginate-color:#999}div#\:\$p>svg>foreignObject>section>:last-child,div#\:\$p>svg>foreignObject>section[data-footer]>:nth-last-child(2){margin-bottom:0}div#\:\$p>svg>foreignObject>section>:first-child,div#\:\$p>svg>foreignObject>section>header:first-child+*{margin-top:0}div#\:\$p>svg>foreignObject>section:after{bottom:21px;color:var(--paginate-color);font-size:24px;padding:0;position:absolute;right:30px}div#\:\$p>svg>foreignObject>section:after{--marpit-root-font-size:24px}div#\:\$p>svg>foreignObject>section[data-color] :is(h1,marp-h1),div#\:\$p>svg>foreignObject>section[data-color] :is(h2,marp-h2),div#\:\$p>svg>foreignObject>section[data-color] :is(h3,marp-h3),div#\:\$p>svg>foreignObject>section[data-color] :is(h4,marp-h4),div#\:\$p>svg>foreignObject>section[data-color] :is(h5,marp-h5),div#\:\$p>svg>foreignObject>section[data-color] :is(h6,marp-h6){color:currentcolor}div#\:\$p>svg>foreignObject>section[data-marpit-advanced-background=background]{columns:initial!important;display:block!important;padding:0!important}div#\:\$p>svg>foreignObject>section[data-marpit-advanced-background=background]:after,div#\:\$p>svg>foreignObject>section[data-marpit-advanced-background=background]:before,div#\:\$p>svg>foreignObject>section[data-marpit-advanced-background=content]:after,div#\:\$p>svg>foreignObject>section[data-marpit-advanced-background=content]:before{display:none!important}div#\:\$p>svg>foreignObject>section[data-marpit-advanced-background=background]>div[data-marpit-advanced-background-container]{all:initial;display:flex;flex-direction:row;height:100%;overflow:hidden;width:100%}div#\:\$p>svg>foreignObject>section[data-marpit-advanced-background=background]>div[data-marpit-advanced-background-container][data-marpit-advanced-background-direction=vertical]{flex-direction:column}div#\:\$p>svg>foreignObject>section[data-marpit-advanced-background=background][data-marpit-advanced-background-split]>div[data-marpit-advanced-background-container]{width:var(--marpit-advanced-background-split,50%)}div#\:\$p>svg>foreignObject>section[data-marpit-advanced-background=background][data-marpit-advanced-background-split=right]>div[data-marpit-advanced-background-container]{margin-left:calc(100% - var(--marpit-advanced-background-split, 50%))}div#\:\$p>svg>foreignObject>section[data-marpit-advanced-background=background]>div[data-marpit-advanced-background-container]>figure{all:initial;background-position:center;background-repeat:no-repeat;background-size:cover;flex:auto;margin:0}div#\:\$p>svg>foreignObject>section[data-marpit-advanced-background=content],div#\:\$p>svg>foreignObject>section[data-marpit-advanced-background=pseudo]{background:transparent!important}div#\:\$p>svg>foreignObject>section[data-marpit-advanced-background=pseudo],div#\:\$p>svg[data-marpit-svg]>foreignObject[data-marpit-advanced-background=pseudo]{pointer-events:none!important}div#\:\$p>svg>foreignObject>section[data-marpit-advanced-background-split]{width:100%;height:100%}</style></head><body><div class="bespoke-marp-osc"><button data-bespoke-marp-osc="prev" tabindex="-1" title="Previous slide">Previous slide</button><span data-bespoke-marp-osc="page"></span><button data-bespoke-marp-osc="next" tabindex="-1" title="Next slide">Next slide</button><button data-bespoke-marp-osc="fullscreen" tabindex="-1" title="Toggle fullscreen (f)">Toggle fullscreen</button><button data-bespoke-marp-osc="presenter" tabindex="-1" title="Open presenter view (p)">Open presenter view</button></div><div id=":$p"><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="1" data-theme="default" style="--theme:default;">
<h1 is="marp-h1" data-auto-scaling id="from-crowd-counting-to-fish-school-counting-using-deep-learning">From Crowd Counting to Fish School Counting Using Deep Learning</h1>
<h6 id="presenter%E7%8E%8B%E5%AE%87%E8%88%AA">Presenter：王宇航</h6>
<h6 id="date2023-09-08">Date：2023-09-08</h6>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="2" data-paginate="true" data-theme="default" data-marpit-pagination="2" data-marpit-pagination-total="56" style="--paginate:true;--theme:default;">
<h1 id="menu">Menu</h1>
<ol>
<li>Crowd Counting</li>
<li>Fish Counting</li>
<li>Learning Tools Sharing</li>
</ol>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section data-paginate="true" data-header="1. Crowd Counting" data-theme="default" data-marpit-pagination="3" data-marpit-pagination-total="56" style="--paginate:true;--header:1. Crowd Counting;--theme:default;--marpit-advanced-background-split:50%;" data-marpit-advanced-background="background" data-marpit-advanced-background-split="right"><div data-marpit-advanced-background-container="true" data-marpit-advanced-background-direction="horizontal"><figure style="background-image:url(&quot;./image/crowd%20counting%20intro.jpg&quot;);background-size:auto 4in;"></figure></div></section></foreignObject><foreignObject width="50%" height="720"><section id="3" data-paginate="true" data-header="1. Crowd Counting" data-theme="default" data-marpit-pagination="3" data-marpit-pagination-total="56" style="--paginate:true;--header:1. Crowd Counting;--theme:default;--marpit-advanced-background-split:50%;" data-marpit-advanced-background="content" data-marpit-advanced-background-split="right">
<header>1. Crowd Counting</header>

<h1 id="1-crowd-counting">1. Crowd Counting</h1>
<p>人群计数，直白的讲就是一种通过计算机计算或估计图像中人数的技术。通过对人群聚集的分析，可以帮助城市管理者、大型活动组织方实时了解人群拥挤情况。例如在疫情期间，就需要通过人群计数，来判断人群的拥挤程度，防止疫情的传播。目前主要有三种方法来解决人群计数问题。</p>
</section>
</foreignObject><foreignObject width="1280" height="720" data-marpit-advanced-background="pseudo"><section data-paginate="true" data-header="1. Crowd Counting" data-theme="default" data-marpit-pagination="3" data-marpit-pagination-total="56" style="" data-marpit-advanced-background="pseudo" data-marpit-advanced-background-split="right"></section></foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="4" data-paginate="true" data-header="1. Crowd Counting" data-theme="default" data-marpit-pagination="4" data-marpit-pagination-total="56" style="--paginate:true;--header:1. Crowd Counting;--theme:default;">
<header>1. Crowd Counting</header>
<h2 id="11-detection-based-methods">1.1. Detection based methods</h2>
<p>这个方法中，使用检测框来框选图像中的每个人，检测框即<code>bounding box</code>，这个要求每个人的轮廓足够清楚，比较适合检测面孔，但是当图片或视频中存在密集的人群时，无法给出令人满意的结果。因为图像中人群非常密集时，每个人的特征就难以区分。</p>
<p><img src="./image/detection%20based.jpg" alt="" style="height:3in;" /></p>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="5" data-paginate="true" data-header="1. Crowd Counting" data-theme="default" data-marpit-pagination="5" data-marpit-pagination-total="56" style="--paginate:true;--header:1. Crowd Counting;--theme:default;">
<header>1. Crowd Counting</header>
<h2 id="12-regression-based-methods">1.2. Regression based methods</h2>
<p>因为基于目标检测的方法在人群很密集的情况下效果不好，因此衍生出了基于回归的方法。但是基于回归的方法是将图像直接映射成具体的人数，听起似乎符合逻辑，但是这种方法所得到的结果无法理解人群的分布，所以并不是最好的方法</p>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="6" data-paginate="true" data-header="1. Crowd Counting" data-theme="default" data-marpit-pagination="6" data-marpit-pagination-total="56" style="--paginate:true;--header:1. Crowd Counting;--theme:default;">
<header>1. Crowd Counting</header>
<h2 id="13-density-estimation-based-methods-with-deep-learning">1.3. Density estimation based methods with deep learning</h2>
<p>基于密度估计的方法，可以将一个图像映射成一个人群的密度图，并通过密度图再计算出的一个图像的人数。这个方法不仅可以知道人群的密度分布，也知道一个图像中人的数量，再配合深度学习模型，是目前主流的预测人群数量的方法</p>
<p><img src="./image/density.p%20based.png" alt="" /></p>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="7" data-paginate="true" data-header="1. Crowd Counting" data-theme="default" data-marpit-pagination="7" data-marpit-pagination-total="56" style="--paginate:true;--header:1. Crowd Counting;--theme:default;">
<header>1. Crowd Counting</header>
<h2 id="14-paper-reading">1.4. Paper reading</h2>
<p>我认为如果要想快速掌握这些方法的具体使用，应该搜素这领域这几年的一些重要的论文，尤其具有转折点的论文，就是说未来的论文都是基于他的方法进行修改。</p>
<p>在计算机视觉领域，有三大顶会：</p>
<ul>
<li><strong>CVPR</strong> - Conference on Computer Vision and Pattern Recognition</li>
<li><strong>ICCV</strong> - International Conference on Computer Vision</li>
<li><strong>ECCV</strong> - European Conference on Computer Vision</li>
</ul>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section data-paginate="true" data-header="1. Crowd Counting" data-theme="default" data-marpit-pagination="8" data-marpit-pagination-total="56" style="--paginate:true;--header:1. Crowd Counting;--theme:default;--marpit-advanced-background-split:50%;" data-marpit-advanced-background="background" data-marpit-advanced-background-split="left"><div data-marpit-advanced-background-container="true" data-marpit-advanced-background-direction="horizontal"><figure style="background-image:url(&quot;./image/mcnn%20paper.png&quot;);background-size:auto 4in;"></figure></div></section></foreignObject><foreignObject width="50%" height="720" x="50%"><section id="8" data-paginate="true" data-header="1. Crowd Counting" data-theme="default" data-marpit-pagination="8" data-marpit-pagination-total="56" style="--paginate:true;--header:1. Crowd Counting;--theme:default;--marpit-advanced-background-split:50%;" data-marpit-advanced-background="content" data-marpit-advanced-background-split="left">
<header>1. Crowd Counting</header>
<p style="font-size: 32px;">经过一系列的搜索，发现 CVPR 的 2016 年的一篇论文特别重要，后面的论文都是基于他的方法或者数据集进行训练。这篇论文创新点是通过神经网络将图像映射成密度图，并且开创了一个全新的数据集，<strong>Shanghaitech</strong>，这个数据集如今已成为业内性能指标必刷榜之一。虽然这篇论文年代已久，但是很值得学习</p>
</section>
</foreignObject><foreignObject width="1280" height="720" data-marpit-advanced-background="pseudo"><section data-paginate="true" data-header="1. Crowd Counting" data-theme="default" data-marpit-pagination="8" data-marpit-pagination-total="56" style="" data-marpit-advanced-background="pseudo" data-marpit-advanced-background-split="left"></section></foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="9" data-paginate="true" data-header="1. Crowd Counting" data-footer="Single-Image Crowd Counting via Multi-Column Convolutional Neural Network-CVPR 2016" data-theme="default" data-marpit-pagination="9" data-marpit-pagination-total="56" style="--paginate:true;--header:1. Crowd Counting;--footer:Single-Image Crowd Counting via Multi-Column Convolutional Neural Network-CVPR 2016;--theme:default;">
<header>1. Crowd Counting</header>

<p>这篇论文的背景是 2015 年上海发生了严重踩踏事件，造成了 35 人死亡，因此研究人群计数越来越重要。我认为这篇论文有以下重要之处：</p>
<ol>
<li>如何生成密度图</li>
<li>loss function 是什么样的</li>
<li>使用什么样的评价指标</li>
</ol>
<p>在认真阅读完这篇论文以及复现其代码后，就会很清楚计数问题该怎么解决</p>
<footer>Single-Image Crowd Counting via Multi-Column Convolutional Neural Network-CVPR 2016</footer>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="10" data-paginate="true" data-header="1.4. Paper reading" data-footer="Single-Image Crowd Counting via Multi-Column Convolutional Neural Network-CVPR 2016" data-theme="default" data-marpit-pagination="10" data-marpit-pagination-total="56" style="--paginate:true;--header:1.4. Paper reading;--footer:Single-Image Crowd Counting via Multi-Column Convolutional Neural Network-CVPR 2016;--theme:default;">
<header>1.4. Paper reading</header>

<h3 id="141-density-map-via-geometry-adaptive-kernels">1.4.1 Density map via geometry-adaptive kernels</h3>
<p>由于神经网络需要学习<code>image X</code>到<code>groud true density map Y</code>的映射关系，因此所提供给模型的密度图的质量非常关键，这篇论文提出了<code>geometry-adaptive kernels</code>。</p>
<footer>Single-Image Crowd Counting via Multi-Column Convolutional Neural Network-CVPR 2016</footer>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section data-paginate="true" data-header="1.4. Paper reading" data-footer="Single-Image Crowd Counting via Multi-Column Convolutional Neural Network-CVPR 2016" data-theme="default" data-marpit-pagination="11" data-marpit-pagination-total="56" style="--paginate:true;--header:1.4. Paper reading;--footer:Single-Image Crowd Counting via Multi-Column Convolutional Neural Network-CVPR 2016;--theme:default;--marpit-advanced-background-split:50%;" data-marpit-advanced-background="background" data-marpit-advanced-background-split="right"><div data-marpit-advanced-background-container="true" data-marpit-advanced-background-direction="horizontal"><figure style="background-image:url(&quot;./image/delta%20definition.png&quot;);background-size:auto 2in;"></figure></div></section></foreignObject><foreignObject width="50%" height="720"><section id="11" data-paginate="true" data-header="1.4. Paper reading" data-footer="Single-Image Crowd Counting via Multi-Column Convolutional Neural Network-CVPR 2016" data-theme="default" data-marpit-pagination="11" data-marpit-pagination-total="56" style="--paginate:true;--header:1.4. Paper reading;--footer:Single-Image Crowd Counting via Multi-Column Convolutional Neural Network-CVPR 2016;--theme:default;--marpit-advanced-background-split:50%;" data-marpit-advanced-background="content" data-marpit-advanced-background-split="right">
<header>1.4. Paper reading</header>
<p>首先将图像转换成一个密度图通过<code>delta function δ(x − xi)</code>. 这个 delta function 原来是<code>δ(x)</code>，这个函数很奇怪，因为它不是一个传统的函数，而是一个分布函数。这个函数在 x 不为 0 处的值都是 0，但是对这个函数进行积分，结果却是 1，原因是在 0 处的值为 ∞</p>
<footer>Single-Image Crowd Counting via Multi-Column Convolutional Neural Network-CVPR 2016</footer>
</section>
</foreignObject><foreignObject width="1280" height="720" data-marpit-advanced-background="pseudo"><section data-paginate="true" data-header="1.4. Paper reading" data-footer="Single-Image Crowd Counting via Multi-Column Convolutional Neural Network-CVPR 2016" data-theme="default" data-marpit-pagination="11" data-marpit-pagination-total="56" style="" data-marpit-advanced-background="pseudo" data-marpit-advanced-background-split="right"></section></foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section data-paginate="true" data-header="1.4. Paper reading" data-footer="Single-Image Crowd Counting via Multi-Column Convolutional Neural Network-CVPR 2016" data-theme="default" data-marpit-pagination="12" data-marpit-pagination-total="56" style="--paginate:true;--header:1.4. Paper reading;--footer:Single-Image Crowd Counting via Multi-Column Convolutional Neural Network-CVPR 2016;--theme:default;--marpit-advanced-background-split:50%;" data-marpit-advanced-background="background" data-marpit-advanced-background-split="right"><div data-marpit-advanced-background-container="true" data-marpit-advanced-background-direction="vertical"><figure style="background-image:url(&quot;./image/delta%20function.png&quot;);background-size:auto 2in;"></figure></div></section></foreignObject><foreignObject width="50%" height="720"><section id="12" data-paginate="true" data-header="1.4. Paper reading" data-footer="Single-Image Crowd Counting via Multi-Column Convolutional Neural Network-CVPR 2016" data-theme="default" data-marpit-pagination="12" data-marpit-pagination-total="56" style="--paginate:true;--header:1.4. Paper reading;--footer:Single-Image Crowd Counting via Multi-Column Convolutional Neural Network-CVPR 2016;--theme:default;--marpit-advanced-background-split:50%;" data-marpit-advanced-background="content" data-marpit-advanced-background-split="right">
<header>1.4. Paper reading</header>
<p>这些公式直观上不好理解，放到图像中比较好理解了。就是在图像某个 pixel 上有人头，那么这个 pixel 的值就是 1，如果图像中有 N 个人头，那么就用右边这个函数表示</p>

<p>通过这个方法，我们可以得到一个密度图，就是这个图像只有在有人头的 pixel 值为 1，其他 pixel 全是 0，对密度图的每个 pixel 进行求和运算，就能得到这个密度图人数</p>
<pre is="marp-pre" data-auto-scaling="downscale-only"><code class="language-python">count = np.<span class="hljs-built_in">sum</span>(density_img)
</code></pre>
<footer>Single-Image Crowd Counting via Multi-Column Convolutional Neural Network-CVPR 2016</footer>
</section>
</foreignObject><foreignObject width="1280" height="720" data-marpit-advanced-background="pseudo"><section data-paginate="true" data-header="1.4. Paper reading" data-footer="Single-Image Crowd Counting via Multi-Column Convolutional Neural Network-CVPR 2016" data-theme="default" data-marpit-pagination="12" data-marpit-pagination-total="56" style="" data-marpit-advanced-background="pseudo" data-marpit-advanced-background-split="right"></section></foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section data-paginate="true" data-header="1.4. Paper reading" data-footer="Single-Image Crowd Counting via Multi-Column Convolutional Neural Network-CVPR 2016" data-theme="default" data-marpit-pagination="13" data-marpit-pagination-total="56" style="--paginate:true;--header:1.4. Paper reading;--footer:Single-Image Crowd Counting via Multi-Column Convolutional Neural Network-CVPR 2016;--theme:default;--marpit-advanced-background-split:50%;" data-marpit-advanced-background="background" data-marpit-advanced-background-split="right"><div data-marpit-advanced-background-container="true" data-marpit-advanced-background-direction="vertical"><figure style="background-image:url(&quot;./image/gaussian%20kernel.png&quot;);background-size:6in auto;"></figure><figure style="background-image:url(&quot;./image/diff%20sigma.png&quot;);background-size:6in auto;"></figure></div></section></foreignObject><foreignObject width="50%" height="720"><section id="13" data-paginate="true" data-header="1.4. Paper reading" data-footer="Single-Image Crowd Counting via Multi-Column Convolutional Neural Network-CVPR 2016" data-theme="default" data-marpit-pagination="13" data-marpit-pagination-total="56" style="--paginate:true;--header:1.4. Paper reading;--footer:Single-Image Crowd Counting via Multi-Column Convolutional Neural Network-CVPR 2016;--theme:default;--marpit-advanced-background-split:50%;" data-marpit-advanced-background="content" data-marpit-advanced-background-split="right">
<header>1.4. Paper reading</header>
<p>但是这样的密度图还是不能拿来训练的，论文中指出，需要将密度图转换为<strong>连续的密度图</strong>，即将密度图使用高斯核进行卷积。高斯核是一个高斯分布的核，由两个参数来控制，窗口的<code>size</code>，以及扩散参数(variance)<code>σ</code>.<code>σ</code>决定了高斯核里每个位置的权重</p>
<footer>Single-Image Crowd Counting via Multi-Column Convolutional Neural Network-CVPR 2016</footer>
</section>
</foreignObject><foreignObject width="1280" height="720" data-marpit-advanced-background="pseudo"><section data-paginate="true" data-header="1.4. Paper reading" data-footer="Single-Image Crowd Counting via Multi-Column Convolutional Neural Network-CVPR 2016" data-theme="default" data-marpit-pagination="13" data-marpit-pagination-total="56" style="" data-marpit-advanced-background="pseudo" data-marpit-advanced-background-split="right"></section></foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="14" data-paginate="true" data-header="1.4. Paper reading" data-footer="Single-Image Crowd Counting via Multi-Column Convolutional Neural Network-CVPR 2016" data-theme="default" data-marpit-pagination="14" data-marpit-pagination-total="56" style="--paginate:true;--header:1.4. Paper reading;--footer:Single-Image Crowd Counting via Multi-Column Convolutional Neural Network-CVPR 2016;--theme:default;">
<header>1.4. Paper reading</header>
<p>通常情况下，图像经过的高斯核卷积，这个高斯核的<code>σ</code>都是固定的。但是作者认为应该根据图像中不同人的人头大小，自适应的更改对应<code>σ</code>，从而卷积时对应的卷积核就权重就会改变。但是由于照片拍摄下来是有扭曲的，不能反映真实的 3D 场景。照片中的一个人头与周围<code>k</code>个最近的人头的距离，可以反映这样几何扭曲的情况,并且论文中也指出人头的大小与这个距离有关。因此作者提出<code>geometry-adaptive kernels</code>，</p>
<p><img src="./image/adaptive.png" alt="" style="height:2in;" /></p>
<p>第一项表示使用<code>delta function H(x)</code>所生成的密度图，第二项使用<code>geometry-adaptive kernels</code>对密度图进行卷积。</p>
<footer>Single-Image Crowd Counting via Multi-Column Convolutional Neural Network-CVPR 2016</footer>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="15" data-paginate="true" data-header="1.4. Paper reading" data-footer="Single-Image Crowd Counting via Multi-Column Convolutional Neural Network-CVPR 2016" data-theme="default" data-marpit-pagination="15" data-marpit-pagination-total="56" style="--paginate:true;--header:1.4. Paper reading;--footer:Single-Image Crowd Counting via Multi-Column Convolutional Neural Network-CVPR 2016;--theme:default;">
<header>1.4. Paper reading</header>
<p>训练集的<code>train_X</code>和<code>train_Y</code>如图所示:<br />
可以看出人群计数要解决的图像，都是人非常多的图像，几百到几千的氛围</p>
<p><img src="./image/density%20map.png" alt="" /></p>
<footer>Single-Image Crowd Counting via Multi-Column Convolutional Neural Network-CVPR 2016</footer>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="16" data-paginate="true" data-header="1.4. Paper reading" data-footer="Single-Image Crowd Counting via Multi-Column Convolutional Neural Network-CVPR 2016" data-theme="default" data-marpit-pagination="16" data-marpit-pagination-total="56" style="--paginate:true;--header:1.4. Paper reading;--footer:Single-Image Crowd Counting via Multi-Column Convolutional Neural Network-CVPR 2016;--theme:default;">
<header>1.4. Paper reading</header>
<h3 id="142-multi-column-cnn-for-density-map-estimation">1.4.2. Multi-column CNN for density map estimation</h3>
<p>本篇论文提出了多列的 CNN 神经网络<code>MCNN</code>，有三个分支，每个分支的<code>kernel size</code>都不一样，这样的目的是让不同分支的神经网络可以获取图像中不同尺寸的人头大小。除了<code>filter</code>的<code>kernel size</code>不一样，三列网络的其他设置都是一样的</p>
<blockquote>
<p>MCNN is motivated by MDNN（Multi-column deep neural networks for image classification）with 2 max pooling layers</p>
</blockquote>
<p><img src="./image/MCNN.png" alt="" style="height:3in;" /></p>
<footer>Single-Image Crowd Counting via Multi-Column Convolutional Neural Network-CVPR 2016</footer>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="17" data-paginate="true" data-header="1.4. Paper reading" data-footer="Single-Image Crowd Counting via Multi-Column Convolutional Neural Network-CVPR 2016" data-theme="default" data-marpit-pagination="17" data-marpit-pagination-total="56" style="--paginate:true;--header:1.4. Paper reading;--footer:Single-Image Crowd Counting via Multi-Column Convolutional Neural Network-CVPR 2016;--theme:default;">
<header>1.4. Paper reading</header>
<h3 id="143-loss-function">1.4.3. Loss function</h3>
<p>为了让模型预测的密度图与<code>ground true density map</code>尽可能的一致，使用了如下的<code>loss function</code>。这里对每一个样本使用了<code>L2 norms</code>。</p>
<p><img src="./image/loss%20for%20density.png" alt="h:in" /></p>
<blockquote>
<p>The <code>norm</code> acts on a vector. The different norms are defined as follows:<br />
<img src="./image/norm.png" alt="" style="height:2in;" /></p>
</blockquote>
<footer>Single-Image Crowd Counting via Multi-Column Convolutional Neural Network-CVPR 2016</footer>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="18" data-paginate="true" data-header="1.4. Paper reading" data-footer="Single-Image Crowd Counting via Multi-Column Convolutional Neural Network-CVPR 2016" data-theme="default" data-marpit-pagination="18" data-marpit-pagination-total="56" style="--paginate:true;--header:1.4. Paper reading;--footer:Single-Image Crowd Counting via Multi-Column Convolutional Neural Network-CVPR 2016;--theme:default;">
<header>1.4. Paper reading</header>
<h3 id="144-optimizer-and-pretrain">1.4.4. Optimizer and Pretrain</h3>
<p>可能当时没有出现 Adam optimizer，论文中使用的是<code>stochastic gradient descent(SGD)</code>。在模型训练之前，作者让每个分支都对数据先进行训练，最后将三个分支合并起来<code>fine-tune</code>所有的参数。如果训练集的数量较少，作者建议那么只会训练最后一层，前面几层都会被固定。</p>
<h3 id="145-evaluation-metric">1.4.5. Evaluation metric</h3>
<p><img src="./image/Evaluation%20metric.png" alt="" style="height:2in;" /></p>
<footer>Single-Image Crowd Counting via Multi-Column Convolutional Neural Network-CVPR 2016</footer>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="19" data-paginate="true" data-header="1.4. Paper reading" data-footer="Single-Image Crowd Counting via Multi-Column Convolutional Neural Network-CVPR 2016" data-theme="default" data-marpit-pagination="19" data-marpit-pagination-total="56" style="--paginate:true;--header:1.4. Paper reading;--footer:Single-Image Crowd Counting via Multi-Column Convolutional Neural Network-CVPR 2016;--theme:default;">
<header>1.4. Paper reading</header>
<h3 id="146-shanghaitech-dataset">1.4.6. Shanghaitech dataset</h3>
<p>这篇论文之所以重要，是因为它收集并开源了一个全新的数据集，这个数据集分为<code>PartA</code>和<code>PartB</code>。可以看出<code>PartA</code>的图像中，人数远大于<code>PartB</code>。人数越大范围的数据集，训练出来的<code>MAE</code>都会偏高，这是无法避免的。</p>
<p><img src="./image/crowd%20counts%20shanghai.png" alt="" style="height:3in;" /></p>
<blockquote>
<p><code>PartA</code>, using <code>geometry-adaptive kernels</code> to generate the density maps<br />
<code>PartB</code>, using <code>same spread in Gaussian kernel</code> since the crowd is relatively sparse</p>
</blockquote>
<footer>Single-Image Crowd Counting via Multi-Column Convolutional Neural Network-CVPR 2016</footer>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section data-paginate="true" data-header="1.4. Paper reading" data-footer="Single-Image Crowd Counting via Multi-Column Convolutional Neural Network-CVPR 2016" data-theme="default" data-marpit-pagination="20" data-marpit-pagination-total="56" style="--paginate:true;--header:1.4. Paper reading;--footer:Single-Image Crowd Counting via Multi-Column Convolutional Neural Network-CVPR 2016;--theme:default;--marpit-advanced-background-split:50%;" data-marpit-advanced-background="background" data-marpit-advanced-background-split="right"><div data-marpit-advanced-background-container="true" data-marpit-advanced-background-direction="horizontal"><figure style="background-image:url(&quot;./image/Comparison%20of%20different%20loss%20functions.png&quot;);background-size:auto 5in;"></figure></div></section></foreignObject><foreignObject width="50%" height="720"><section id="20" data-paginate="true" data-header="1.4. Paper reading" data-footer="Single-Image Crowd Counting via Multi-Column Convolutional Neural Network-CVPR 2016" data-theme="default" data-marpit-pagination="20" data-marpit-pagination-total="56" style="--paginate:true;--header:1.4. Paper reading;--footer:Single-Image Crowd Counting via Multi-Column Convolutional Neural Network-CVPR 2016;--theme:default;--marpit-advanced-background-split:50%;" data-marpit-advanced-background="content" data-marpit-advanced-background-split="right">
<header>1.4. Paper reading</header>
<h3 id="146-comparison-of-different-loss-functions">1.4.6. Comparison of different loss functions</h3>
<p>除了前面介绍的 loss function，还有另一种 loss function，这种 loss，不是将 <code>predicted density map</code> 与 <code>ground true density map</code> 进行对比，而是将 <code>predicted count</code> 和 <code>actual count</code> 进行对比。人数越多，预测出来的<code>MAE</code> 也越大。</p>
<p><img src="./image/loss%20for%20counts.png" alt="" style="height:1in;" /></p>

<blockquote>
<p>LBP+RR: regression based<br />
MCNN-CCR: loss for counts</p>
</blockquote>
<footer>Single-Image Crowd Counting via Multi-Column Convolutional Neural Network-CVPR 2016</footer>
</section>
</foreignObject><foreignObject width="1280" height="720" data-marpit-advanced-background="pseudo"><section data-paginate="true" data-header="1.4. Paper reading" data-footer="Single-Image Crowd Counting via Multi-Column Convolutional Neural Network-CVPR 2016" data-theme="default" data-marpit-pagination="20" data-marpit-pagination-total="56" style="" data-marpit-advanced-background="pseudo" data-marpit-advanced-background-split="right"></section></foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="21" data-paginate="true" data-header="1.4. Paper reading" data-footer="CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018" data-theme="default" data-marpit-pagination="21" data-marpit-pagination-total="56" style="--paginate:true;--header:1.4. Paper reading;--footer:CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018;--theme:default;">
<header>1.4. Paper reading</header>

<h3 id="147-csrnet-paper">1.4.7. CSRNet Paper</h3>
<p>在 MCNN 这篇论文之后，又出现了一篇很重要的论文，来自 CVPR-2018 的一篇,这篇论文的代码在 github 上的 stars 有 600 多，算是很多人阅读过。</p>
<p><img src="./image/CSR%20paper.png" alt="" /><br />
<img src="./image/CSR%20stars.png" alt="" /></p>
<footer>CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018</footer>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="22" data-paginate="true" data-header="1.4. Paper reading" data-footer="CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018" data-theme="default" data-marpit-pagination="22" data-marpit-pagination-total="56" style="--paginate:true;--header:1.4. Paper reading;--footer:CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018;--theme:default;">
<header>1.4. Paper reading</header>
<p>这篇论文所使用的密度图生成方法，loss function 都与 MCNN 一致，但是模型不同，最后精度也从 100 多提高到 60 多，可以说是巨大的提高。论文经过试验直接表明：</p>
<ul>
<li>多列的 CNN 模型的性能还不如只有一列普通的，更深的 CNN 模型</li>
<li>MCNN 的三列 CNN 中，性能表现都一致，不是原文说的那样不同列可以提取不同的特征</li>
<li>MCNN 非常不好训练，因为需要事先对每一列进行预训练</li>
</ul>
<footer>CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018</footer>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section data-paginate="true" data-header="1.4. Paper reading" data-footer="CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018" data-theme="default" data-marpit-pagination="23" data-marpit-pagination-total="56" style="--paginate:true;--header:1.4. Paper reading;--footer:CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018;--theme:default;--marpit-advanced-background-split:50%;" data-marpit-advanced-background="background" data-marpit-advanced-background-split="right"><div data-marpit-advanced-background-container="true" data-marpit-advanced-background-direction="horizontal"><figure style="background-image:url(&quot;./image/CSR%20summary.png&quot;);background-size:auto 6in;"></figure></div></section></foreignObject><foreignObject width="50%" height="720"><section id="23" data-paginate="true" data-header="1.4. Paper reading" data-footer="CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018" data-theme="default" data-marpit-pagination="23" data-marpit-pagination-total="56" style="--paginate:true;--header:1.4. Paper reading;--footer:CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018;--theme:default;--marpit-advanced-background-split:50%;" data-marpit-advanced-background="content" data-marpit-advanced-background-split="right">
<header>1.4. Paper reading</header>
<h3 id="148-csrnet-model">1.4.8. CSRNet model</h3>
<p><code>CSR(Congested Scene Recognition)</code>模型它使用<code>vgg-16</code>作为<code>front end</code>，并使用<code>Dilated convolution</code>作为<code>back end</code>。<code>vgg-16</code>是一个配置非常简单的 CNN，且深度较深的模型，每一层配置全是<code>3x3 kernels</code>，这使得 CSR 模型十分简洁</p>
<footer>CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018</footer>
</section>
</foreignObject><foreignObject width="1280" height="720" data-marpit-advanced-background="pseudo"><section data-paginate="true" data-header="1.4. Paper reading" data-footer="CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018" data-theme="default" data-marpit-pagination="23" data-marpit-pagination-total="56" style="" data-marpit-advanced-background="pseudo" data-marpit-advanced-background-split="right"></section></foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="24" data-paginate="true" data-header="1.4. Paper reading" data-footer="CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018" data-theme="default" data-marpit-pagination="24" data-marpit-pagination-total="56" style="--paginate:true;--header:1.4. Paper reading;--footer:CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018;--theme:default;">
<header>1.4. Paper reading</header>
<h3 id="149-dilated-convolution">1.4.9. Dilated convolution</h3>
<p>在模型的后端，使用了<code>Dilated convolution</code>。这是一种扩散卷积，扩散的幅度<code>dilation rate</code>来决定,通过不同<code>dilation rate</code>来提取更大范围的特征，优势是</p>
<ol>
<li>kernal size 一直是 3x3，使得模型参数的数量不会变化。</li>
</ol>
<p><img src="./image/Dilated%20convolution.png" alt="" style="height:4in;" /></p>
<footer>CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018</footer>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="25" data-paginate="true" data-header="1.4. Paper reading" data-footer="CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018" data-theme="default" data-marpit-pagination="25" data-marpit-pagination-total="56" style="--paginate:true;--header:1.4. Paper reading;--footer:CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018;--theme:default;">
<header>1.4. Paper reading</header>
<ol start="2">
<li>可以替代 maxpooling+convolution layer，所输出的信息更详细</li>
</ol>
<p><img src="./image/dilation%20advantage.png" alt="" /></p>
<footer>CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018</footer>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="26" data-paginate="true" data-header="1.5. Code Implementation" data-footer="CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018" data-theme="default" data-marpit-pagination="26" data-marpit-pagination-total="56" style="--paginate:true;--header:1.5. Code Implementation;--footer:CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018;--theme:default;">
<header>1.5. Code Implementation</header>

<h2 id="15-code-implementation">1.5. Code Implementation</h2>
<p>经过上面两篇的学习，我开始使用 Pytorch 来复现两篇论文的代码，由于 MCNN 论文是使用 Caffe 来实现的，这个是很久以前的框架，由于 Pytorch 的出现，越来越少的人会去使用 Caffe。因此只用 pytorch 简单写了一下第一篇论文的模型。</p>
<footer>CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018</footer>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section data-paginate="true" data-header="1.5. Code Implementation" data-footer="CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018" data-theme="default" data-marpit-pagination="27" data-marpit-pagination-total="56" style="--paginate:true;--header:1.5. Code Implementation;--footer:CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018;--theme:default;--marpit-advanced-background-split:50%;" data-marpit-advanced-background="background" data-marpit-advanced-background-split="left"><div data-marpit-advanced-background-container="true" data-marpit-advanced-background-direction="horizontal"><figure style="background-image:url(&quot;./image/MCNN%20code.png&quot;);background-size:auto 6in;"></figure></div></section></foreignObject><foreignObject width="50%" height="720" x="50%"><section id="27" data-paginate="true" data-header="1.5. Code Implementation" data-footer="CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018" data-theme="default" data-marpit-pagination="27" data-marpit-pagination-total="56" style="--paginate:true;--header:1.5. Code Implementation;--footer:CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018;--theme:default;--marpit-advanced-background-split:50%;" data-marpit-advanced-background="content" data-marpit-advanced-background-split="left">
<header>1.5. Code Implementation</header>
<h3 id="151-mcnn-code">1.5.1. MCNN code</h3>
<p><br />
<img src="./image/MCNN.png" alt="" /></p>
<footer>CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018</footer>
</section>
</foreignObject><foreignObject width="1280" height="720" data-marpit-advanced-background="pseudo"><section data-paginate="true" data-header="1.5. Code Implementation" data-footer="CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018" data-theme="default" data-marpit-pagination="27" data-marpit-pagination-total="56" style="" data-marpit-advanced-background="pseudo" data-marpit-advanced-background-split="left"></section></foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section data-paginate="true" data-header="1.5. Code Implementation" data-footer="CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018" data-theme="default" data-marpit-pagination="28" data-marpit-pagination-total="56" style="--paginate:true;--header:1.5. Code Implementation;--footer:CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018;--theme:default;--marpit-advanced-background-split:50%;" data-marpit-advanced-background="background" data-marpit-advanced-background-split="left"><div data-marpit-advanced-background-container="true" data-marpit-advanced-background-direction="horizontal"><figure style="background-image:url(&quot;./image/CSR%20code.png&quot;);background-size:contain;"></figure></div></section></foreignObject><foreignObject width="50%" height="720" x="50%"><section id="28" data-paginate="true" data-header="1.5. Code Implementation" data-footer="CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018" data-theme="default" data-marpit-pagination="28" data-marpit-pagination-total="56" style="--paginate:true;--header:1.5. Code Implementation;--footer:CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018;--theme:default;--marpit-advanced-background-split:50%;" data-marpit-advanced-background="content" data-marpit-advanced-background-split="left">
<header>1.5. Code Implementation</header>
<h3 id="152-csr-code">1.5.2. CSR code</h3>
<p><br />
<img src="./image/CSR%20summary.png" alt="" style="height:5in;" /></p>
<footer>CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018</footer>
</section>
</foreignObject><foreignObject width="1280" height="720" data-marpit-advanced-background="pseudo"><section data-paginate="true" data-header="1.5. Code Implementation" data-footer="CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018" data-theme="default" data-marpit-pagination="28" data-marpit-pagination-total="56" style="" data-marpit-advanced-background="pseudo" data-marpit-advanced-background-split="left"></section></foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="29" data-paginate="true" data-header="1.5. Code Implementation" data-footer="CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018" data-theme="default" data-marpit-pagination="29" data-marpit-pagination-total="56" style="--paginate:true;--header:1.5. Code Implementation;--footer:CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018;--theme:default;">
<header>1.5. Code Implementation</header>
<h4 id="153-trianpy-in-csrnet-paper">1.5.3. Trian.py in CSRNet Paper</h4>
<p>大部分的深度学习代码的训练部分，python 代码基本都是面向过程的写法。由于我本人编程习惯，喜欢使用面向对象的方式来写 python，因此在训练，验证部分，我都写到一个 class。我这么写的目的是，我可以很好的在 jupyer notebook 中直接调用这个 class 暴露的方法，来预览我的数据集，模型，以及预测结果。</p>
<pre is="marp-pre" data-auto-scaling="downscale-only"><code class="language-python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">CSRTrain</span>:
  <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, learning_rate=<span class="hljs-number">3e-4</span>, decay=<span class="hljs-number">1e-5</span>, batch_size=<span class="hljs-number">4</span>, test_batch_size=<span class="hljs-number">1</span>, epochs=<span class="hljs-number">400</span>, dataset=<span class="hljs-string">&quot;part_A&quot;</span>, checkpoint_name=<span class="hljs-string">&quot;csr_checkpoint_part_A.pth&quot;</span></span>) -&gt; <span class="hljs-literal">None</span>:
  <span class="hljs-comment"># Hyperparameter</span>
  <span class="hljs-keyword">def</span> <span class="hljs-title function_">set_hyperparameters</span>(<span class="hljs-params">self, learning_rate, decay, batch_size, epochs, test_batch_size</span>):
  <span class="hljs-keyword">def</span> <span class="hljs-title function_">load_dataset</span>(<span class="hljs-params">self</span>):
  <span class="hljs-comment"># data augmentation</span>
  <span class="hljs-keyword">def</span> <span class="hljs-title function_">define_data_augmentation</span>(<span class="hljs-params">self</span>):
  <span class="hljs-comment"># define loss and optimizer</span>
  <span class="hljs-keyword">def</span> <span class="hljs-title function_">complie</span>(<span class="hljs-params">self</span>):
  <span class="hljs-keyword">def</span> <span class="hljs-title function_">train_loop</span>(<span class="hljs-params">self, dataloader: DataLoader, model: nn.Module, loss_fn, optimizer</span>):
  <span class="hljs-keyword">def</span> <span class="hljs-title function_">validation_loop</span>(<span class="hljs-params">self, dataloader: DataLoader, model: nn.Module, loss_fn</span>):
  <span class="hljs-comment"># logging configure</span>
  <span class="hljs-keyword">def</span> <span class="hljs-title function_">set_logging_config</span>(<span class="hljs-params">self</span>):
  <span class="hljs-keyword">def</span> <span class="hljs-title function_">save</span>(<span class="hljs-params">self, loss, mae, mse, model: nn.Module, optimizer</span>):
  <span class="hljs-keyword">def</span> <span class="hljs-title function_">run</span>(<span class="hljs-params">self</span>):
</code></pre>
<footer>CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018</footer>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="30" data-paginate="true" data-header="1.5. Code Implementation" data-footer="CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018" data-theme="default" data-marpit-pagination="30" data-marpit-pagination-total="56" style="--paginate:true;--header:1.5. Code Implementation;--footer:CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018;--theme:default;">
<header>1.5. Code Implementation</header>
<ul>
<li>对 shanghaitech 进行训练时，发现一个问题，由于 shanghaitech 的 PartA 数据集中，每个图像的 shape 都是不一样的，如果使用 resize，势必会导致图像扭曲，这是论文作者不建议的，因为密度图的生成会使用到上面所提到的<code>geometry-adaptive kernels</code>，扭曲之后距离也会发生变化。并且由于 tran_x 和 train_y 都是图像，对 x 进行的修改，必须作用到 y，否则 x 与 y 就不匹配，如果对密度图进行 resize，resize 会使用到插值，势必会影响到密度图的人数。</li>
<li>作者所提供的代码是将 batch size 设置为 1，但是如果将 batch size 设置为 1 的话，loss 会震荡的很厉害,会变成<code>Stochastic gradient descent</code>。所以我死活训练不到论文中要求的精度，并且也有一大批人在 github 的 issue 里向作者提问说，训练的得到的 MAE 特别高，但是作者都没有正面回应，且作者也不提供预训练的模型。</li>
</ul>
<footer>CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018</footer>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="31" data-paginate="true" data-header="1.5. Code Implementation" data-footer="CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018" data-theme="default" data-marpit-pagination="31" data-marpit-pagination-total="56" style="--paginate:true;--header:1.5. Code Implementation;--footer:CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018;--theme:default;">
<header>1.5. Code Implementation</header>
<p><img src="./image/batch%20size1.png" alt="" /></p>
<footer>CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018</footer>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="32" data-paginate="true" data-header="1.5. Code Implementation" data-footer="CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018" data-theme="default" data-marpit-pagination="32" data-marpit-pagination-total="56" style="--paginate:true;--header:1.5. Code Implementation;--footer:CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018;--theme:default;">
<header>1.5. Code Implementation</header>
<ol>
<li>首先我将 <code>Part A</code> 的数据进行 <code>crop</code>，由于有的图像很小，不够裁剪，因此需要使用 <code>padding</code>。并且每个图像 <code>crop</code> 成 9 份，前 4 份为图像的四个角，后 5 份为 <code>random crop</code></li>
</ol>
<p><img src="./image/crop%20images.png" alt="" /></p>
<footer>CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018</footer>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="33" data-paginate="true" data-header="1.5. Code Implementation" data-footer="CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018" data-theme="default" data-marpit-pagination="33" data-marpit-pagination-total="56" style="--paginate:true;--header:1.5. Code Implementation;--footer:CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018;--theme:default;">
<header>1.5. Code Implementation</header>
<ol start="2">
<li>其次，我修改了<code>learning rate</code> 和 <code>optimizer</code>，并加了<code>batchnorm</code>层，源代码的 lr 是<code>1e-7</code>,这里模型的配置为 3，即<code>混合dilation rate</code></li>
</ol>
<pre is="marp-pre" data-auto-scaling="downscale-only"><code class="language-python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">complie</span>(<span class="hljs-params">self</span>):
  self.__learning_rate = <span class="hljs-number">3e-4</span>
  self.model = CSRNet(config=<span class="hljs-number">3</span>, freeze_frontend=<span class="hljs-literal">False</span>).to(self.__device)
  self.loss_fn = nn.MSELoss(reduction=<span class="hljs-string">&quot;sum&quot;</span>)
  self.optimizer = torch.optim.Adam(
      params=self.model.parameters(), lr=self.__learning_rate, weight_decay=self.__decay)
</code></pre>
<footer>CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018</footer>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="34" data-paginate="true" data-header="1.5. Code Implementation" data-footer="CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018" data-theme="default" data-marpit-pagination="34" data-marpit-pagination-total="56" style="--paginate:true;--header:1.5. Code Implementation;--footer:CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018;--theme:default;">
<header>1.5. Code Implementation</header>
<ol start="3">
<li>通过将<code>print</code>语句换成<code>logging</code>包，可以让日志保存在单独的文件里，方便我直观的了解训练过程。在生成的日志文件里，可以看到我在第<code>Epoch 151/400</code>就找到最低的 MAE。并且 MAE 比原论文提高了 3 点，注意我这里使用的配置 3 进行训练。</li>
</ol>
<pre is="marp-pre" data-auto-scaling="downscale-only"><code class="language-powershell"><span class="hljs-number">2023</span><span class="hljs-literal">-08-10</span> <span class="hljs-number">13</span>:<span class="hljs-number">01</span>:<span class="hljs-number">55</span>,<span class="hljs-number">456</span> - INFO - Epoch <span class="hljs-number">150</span>/<span class="hljs-number">400</span>
<span class="hljs-number">2023</span><span class="hljs-literal">-08-10</span> <span class="hljs-number">13</span>:<span class="hljs-number">01</span>:<span class="hljs-number">55</span>,<span class="hljs-number">456</span> - INFO - <span class="hljs-literal">-------------------------------</span>
<span class="hljs-number">2023</span><span class="hljs-literal">-08-10</span> <span class="hljs-number">13</span>:<span class="hljs-number">02</span>:<span class="hljs-number">58</span>,<span class="hljs-number">829</span> - INFO - Train Error - batches:  <span class="hljs-number">75</span>/ <span class="hljs-number">75</span> - samples: <span class="hljs-number">300</span>/<span class="hljs-number">300</span> - loss: <span class="hljs-number">7.6168</span> - MAE: <span class="hljs-number">54.4913</span> - MSE: <span class="hljs-number">74.6643</span>
<span class="hljs-number">2023</span><span class="hljs-literal">-08-10</span> <span class="hljs-number">13</span>:<span class="hljs-number">03</span>:<span class="hljs-number">10</span>,<span class="hljs-number">291</span> - INFO - Test Error - batches: <span class="hljs-number">182</span>/<span class="hljs-number">182</span> - samples: <span class="hljs-number">182</span>/<span class="hljs-number">182</span> - loss: <span class="hljs-number">77.2686</span> - MAE: <span class="hljs-number">137.0996</span> - MSE: <span class="hljs-number">184.2028</span>
<span class="hljs-number">2023</span><span class="hljs-literal">-08-10</span> <span class="hljs-number">13</span>:<span class="hljs-number">03</span>:<span class="hljs-number">10</span>,<span class="hljs-number">291</span> - INFO - Epoch <span class="hljs-number">151</span>/<span class="hljs-number">400</span>
<span class="hljs-number">2023</span><span class="hljs-literal">-08-10</span> <span class="hljs-number">13</span>:<span class="hljs-number">03</span>:<span class="hljs-number">10</span>,<span class="hljs-number">291</span> - INFO - <span class="hljs-literal">-------------------------------</span>
<span class="hljs-number">2023</span><span class="hljs-literal">-08-10</span> <span class="hljs-number">13</span>:<span class="hljs-number">04</span>:<span class="hljs-number">13</span>,<span class="hljs-number">518</span> - INFO - Train Error - batches:  <span class="hljs-number">75</span>/ <span class="hljs-number">75</span> - samples: <span class="hljs-number">300</span>/<span class="hljs-number">300</span> - loss: <span class="hljs-number">6.4217</span> - MAE: <span class="hljs-number">39.3705</span> - MSE: <span class="hljs-number">52.0474</span>
<span class="hljs-number">2023</span><span class="hljs-literal">-08-10</span> <span class="hljs-number">13</span>:<span class="hljs-number">04</span>:<span class="hljs-number">24</span>,<span class="hljs-number">946</span> - INFO - Test Error - batches: <span class="hljs-number">182</span>/<span class="hljs-number">182</span> - samples: <span class="hljs-number">182</span>/<span class="hljs-number">182</span> - loss: <span class="hljs-number">76.0832</span> - MAE: <span class="hljs-number">68.3366</span> - MSE: <span class="hljs-number">125.1305</span>
<span class="hljs-number">2023</span><span class="hljs-literal">-08-10</span> <span class="hljs-number">13</span>:<span class="hljs-number">04</span>:<span class="hljs-number">25</span>,<span class="hljs-number">267</span> - INFO - saveing the checkpoint at the error of <span class="hljs-number">76.0832</span> loss, <span class="hljs-number">68.3366</span> mae, <span class="hljs-number">125.1305</span> mse to csr_checkpoint_part_A_fixcrop.pth
<span class="hljs-number">2023</span><span class="hljs-literal">-08-10</span> <span class="hljs-number">13</span>:<span class="hljs-number">04</span>:<span class="hljs-number">25</span>,<span class="hljs-number">267</span> - INFO - Epoch <span class="hljs-number">152</span>/<span class="hljs-number">400</span>
<span class="hljs-number">2023</span><span class="hljs-literal">-08-10</span> <span class="hljs-number">13</span>:<span class="hljs-number">04</span>:<span class="hljs-number">25</span>,<span class="hljs-number">267</span> - INFO - <span class="hljs-literal">-------------------------------</span>
<span class="hljs-number">2023</span><span class="hljs-literal">-08-10</span> <span class="hljs-number">13</span>:<span class="hljs-number">05</span>:<span class="hljs-number">28</span>,<span class="hljs-number">577</span> - INFO - Train Error - batches:  <span class="hljs-number">75</span>/ <span class="hljs-number">75</span> - samples: <span class="hljs-number">300</span>/<span class="hljs-number">300</span> - loss: <span class="hljs-number">9.7540</span> - MAE: <span class="hljs-number">70.0550</span> - MSE: <span class="hljs-number">95.2593</span>
<span class="hljs-number">2023</span><span class="hljs-literal">-08-10</span> <span class="hljs-number">13</span>:<span class="hljs-number">05</span>:<span class="hljs-number">39</span>,<span class="hljs-number">899</span> - INFO - Test Error - batches: <span class="hljs-number">182</span>/<span class="hljs-number">182</span> - samples: <span class="hljs-number">182</span>/<span class="hljs-number">182</span> - loss: <span class="hljs-number">77.8660</span> - MAE: <span class="hljs-number">114.8700</span> - MSE: <span class="hljs-number">175.4805</span>
</code></pre>
<p><img src="./image/CSR%20MAE.png" alt="" style="height:2in;" /></p>
<footer>CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018</footer>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="35" data-paginate="true" data-header="1.5. Code Implementation" data-footer="CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018" data-theme="default" data-marpit-pagination="35" data-marpit-pagination-total="56" style="--paginate:true;--header:1.5. Code Implementation;--footer:CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018;--theme:default;">
<header>1.5. Code Implementation</header>
<p><img src="./image/output.png" alt="" /></p>
<blockquote>
<p>七里山塘</p>
</blockquote>
<footer>CSRNet: Dilated Convolutional Neural Networks for Understanding the Highly Congested Scenes-CVPR 2018</footer>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section data-paginate="true" data-header="1.5. Code Implementation" data-footer="Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021" data-theme="default" data-marpit-pagination="36" data-marpit-pagination-total="56" style="--paginate:true;--header:1.5. Code Implementation;--footer:Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021;--theme:default;--marpit-advanced-background-split:50%;" data-marpit-advanced-background="background" data-marpit-advanced-background-split="right"><div data-marpit-advanced-background-container="true" data-marpit-advanced-background-direction="horizontal"><figure style="background-image:url(&quot;./image/fish%20counting.png&quot;);background-size:auto 4in;"></figure></div></section></foreignObject><foreignObject width="50%" height="720"><section id="36" data-paginate="true" data-header="1.5. Code Implementation" data-footer="Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021" data-theme="default" data-marpit-pagination="36" data-marpit-pagination-total="56" style="--paginate:true;--header:1.5. Code Implementation;--footer:Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021;--theme:default;--marpit-advanced-background-split:50%;" data-marpit-advanced-background="content" data-marpit-advanced-background-split="right">
<header>1.5. Code Implementation</header>
<h1 id="2-fish-school-counting">2. Fish school counting</h1>

<p>鱼群计数我通过看 2021 CVPR 的一篇进行学习,这篇论文的阅读难度明显比前面两篇高很多，主要原因这篇论文对 loss function 进行了修改，并且加入了 <code>self supervision</code>。这里我对我认为有用的内容进行介绍</p>

<blockquote>
<p>Paper written by native speaker is relatively hard to read than those written by Chinese</p>
</blockquote>
<footer>Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021</footer>
</section>
</foreignObject><foreignObject width="1280" height="720" data-marpit-advanced-background="pseudo"><section data-paginate="true" data-header="1.5. Code Implementation" data-footer="Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021" data-theme="default" data-marpit-pagination="36" data-marpit-pagination-total="56" style="" data-marpit-advanced-background="pseudo" data-marpit-advanced-background-split="right"></section></foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section data-paginate="true" data-header="1.5. Code Implementation" data-footer="Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021" data-theme="default" data-marpit-pagination="37" data-marpit-pagination-total="56" style="--paginate:true;--header:1.5. Code Implementation;--footer:Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021;--theme:default;--marpit-advanced-background-split:50%;" data-marpit-advanced-background="background" data-marpit-advanced-background-split="right"><div data-marpit-advanced-background-container="true" data-marpit-advanced-background-direction="horizontal"><figure style="background-image:url(&quot;./image/fish%20distribution.png&quot;);background-size:auto 4in;"></figure></div></section></foreignObject><foreignObject width="50%" height="720"><section id="37" data-paginate="true" data-header="1.5. Code Implementation" data-footer="Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021" data-theme="default" data-marpit-pagination="37" data-marpit-pagination-total="56" style="--paginate:true;--header:1.5. Code Implementation;--footer:Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021;--theme:default;--marpit-advanced-background-split:50%;" data-marpit-advanced-background="content" data-marpit-advanced-background-split="right">
<header>1.5. Code Implementation</header>
<h2 id="21-dataset">2.1. Dataset</h2>
<p>这篇论文是用来计算深海中鱼群的数量，论文中指出：由于在深海，能见度极低，所以用普通相机基本拍不到鱼群，所以得用声纳（Sonar）相机进行拍摄，因为它使用的是声能而不是光能。这个数据集分为 <code>labelled data</code> 和 <code>unlabelled data</code>，前者用于 <code>supervised learning</code>，后者用于 <code>self supervised learning</code></p>
<footer>Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021</footer>
</section>
</foreignObject><foreignObject width="1280" height="720" data-marpit-advanced-background="pseudo"><section data-paginate="true" data-header="1.5. Code Implementation" data-footer="Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021" data-theme="default" data-marpit-pagination="37" data-marpit-pagination-total="56" style="" data-marpit-advanced-background="pseudo" data-marpit-advanced-background-split="right"></section></foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section data-paginate="true" data-header="1.5. Code Implementation" data-footer="Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021" data-theme="default" data-marpit-pagination="38" data-marpit-pagination-total="56" style="--paginate:true;--header:1.5. Code Implementation;--footer:Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021;--theme:default;" data-marpit-advanced-background="background"><div data-marpit-advanced-background-container="true" data-marpit-advanced-background-direction="horizontal"><figure style="background-image:url(&quot;./image/sonar%20perpective%20view.png&quot;);background-size:contain;"></figure></div></section></foreignObject><foreignObject width="1280" height="720"><section id="38" data-paginate="true" data-header="1.5. Code Implementation" data-footer="Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021" data-theme="default" data-marpit-pagination="38" data-marpit-pagination-total="56" style="--paginate:true;--header:1.5. Code Implementation;--footer:Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021;--theme:default;" data-marpit-advanced-background="content">
<header>1.5. Code Implementation</header>
<footer>Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021</footer>
</section>
</foreignObject><foreignObject width="1280" height="720" data-marpit-advanced-background="pseudo"><section data-paginate="true" data-header="1.5. Code Implementation" data-footer="Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021" data-theme="default" data-marpit-pagination="38" data-marpit-pagination-total="56" style="" data-marpit-advanced-background="pseudo"></section></foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section data-paginate="true" data-header="1.5. Code Implementation" data-footer="Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021" data-theme="default" data-marpit-pagination="39" data-marpit-pagination-total="56" style="--paginate:true;--header:1.5. Code Implementation;--footer:Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021;--theme:default;" data-marpit-advanced-background="background"><div data-marpit-advanced-background-container="true" data-marpit-advanced-background-direction="horizontal"><figure style="background-image:url(&quot;./image/unlabelled%20data.png&quot;);background-size:contain;"></figure></div></section></foreignObject><foreignObject width="1280" height="720"><section id="39" data-paginate="true" data-header="1.5. Code Implementation" data-footer="Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021" data-theme="default" data-marpit-pagination="39" data-marpit-pagination-total="56" style="--paginate:true;--header:1.5. Code Implementation;--footer:Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021;--theme:default;" data-marpit-advanced-background="content">
<header>1.5. Code Implementation</header>
<footer>Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021</footer>
</section>
</foreignObject><foreignObject width="1280" height="720" data-marpit-advanced-background="pseudo"><section data-paginate="true" data-header="1.5. Code Implementation" data-footer="Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021" data-theme="default" data-marpit-pagination="39" data-marpit-pagination-total="56" style="" data-marpit-advanced-background="pseudo"></section></foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="40" data-paginate="true" data-header="1.5. Code Implementation" data-footer="Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021" data-theme="default" data-marpit-pagination="40" data-marpit-pagination-total="56" style="--paginate:true;--header:1.5. Code Implementation;--footer:Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021;--theme:default;">
<header>1.5. Code Implementation</header>
<h2 id="23-multi-task-framework">2.3. Multi-task framework</h2>
<ul>
<li>parameter sharing between counting and ranking tasks</li>
</ul>
<p><img src="./image/mutitask%20model.png" alt="" style="height:5in;" /></p>
<footer>Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021</footer>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="41" data-paginate="true" data-header="1.5. Code Implementation" data-footer="Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021" data-theme="default" data-marpit-pagination="41" data-marpit-pagination-total="56" style="--paginate:true;--header:1.5. Code Implementation;--footer:Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021;--theme:default;">
<header>1.5. Code Implementation</header>
<h2 id="24-regularizing-the-loss-term-aleatoric-uncertainty">2.4. Regularizing the loss term: aleatoric uncertainty</h2>
<p><code>counting task</code> 使用的 loss 与 <code>ranking task</code> 是不一样的。在 <code>counting task</code> 中，作者引入了 <code>Aleatoric uncertainty</code>，这个随机不确定性由图片的噪音产生的，比如海豚，网等。为了量化这个不确定性，模型在输出<code>density map</code>的同时，也要学习如何预测<code>noise variance map</code>，使得用户可以知道这个图像所预测的数量可信程度是在怎么样一个范围<img src="./image/loss%20for%20fish%20count.png" alt="" /><img src="./image/sigma%20square.png" alt="" /></p>
<p><img src="./image/Lc%20loss.png" alt="" /> <img src="./image/au%20loss.png" alt="" /> add log σ^2 as <code>predicted noise</code> to penalise the loss and multiply Lc component by <code>e−predicted noise</code>.</p>
<footer>Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021</footer>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="42" data-paginate="true" data-header="1.5. Code Implementation" data-footer="Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021" data-theme="default" data-marpit-pagination="42" data-marpit-pagination-total="56" style="--paginate:true;--header:1.5. Code Implementation;--footer:Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021;--theme:default;">
<header>1.5. Code Implementation</header>
<h2 id="25-regularizing-self-supervised-ranking-task-with-unlabelled-data-in-a-multi-task-network">2.5. Regularizing: self-supervised ranking task with unlabelled data in a multi-task network</h2>
<p><code>ranking task</code>使用了<code>self-supervised learning</code>,就是这些的数据集都没有打上标签，输入的数据是两个图像为一对，第一个图像是大的图像，第二个图像是将第一个进行裁剪获得的小图像，所以第二个图像的人数一定比第一个图像的少。<code>ranking task</code>的 loss 就是基于这个所创造的。我认为这个<code>ranking task</code>特别有用，因为如果没有这个，模型经常会对一个<code>cropped image</code>预测出比原图更大的数量。</p>
<p><img src="./image/ranking%20loss.png" alt="" /> pk is average value over all pixels corresponding to its density map.Loss value will be 0 if predicting the correct order.</p>
<footer>Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021</footer>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="43" data-paginate="true" data-header="1.5. Code Implementation" data-footer="Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021" data-theme="default" data-marpit-pagination="43" data-marpit-pagination-total="56" style="--paginate:true;--header:1.5. Code Implementation;--footer:Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021;--theme:default;">
<header>1.5. Code Implementation</header>
<h2 id="26-complete-loss">2.6. Complete loss</h2>
<p>整个<code>muti task model</code>的<code>loss function</code>就是把上面两个<code>loss term</code>加起来</p>
<p><img src="./image/complete%20loss.png" alt="" style="height:3in;" /></p>
<blockquote>
<p>I think there is something wrong with this paper and its open-source code. I have already raised some issues on the author's GitHub, and I have also submitted PRs for the issues I found in their code. We will talk later.</p>
</blockquote>
<footer>Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021</footer>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="44" data-paginate="true" data-header="1.5. Code Implementation" data-footer="Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021" data-theme="default" data-marpit-pagination="44" data-marpit-pagination-total="56" style="--paginate:true;--header:1.5. Code Implementation;--footer:Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021;--theme:default;">
<header>1.5. Code Implementation</header>
<h2 id="27-conclusion">2.7. Conclusion</h2>
<p>密度图不仅可以得到鱼群的数量，而且还能从中观察到鱼群的分布情况，但真的是这样吗？</p>
<ul>
<li>鱼群在水中可以在三个方向运动的，因此鱼群的聚集和分散也将是在三个方向上。而照片是二维的，它只能反映两个维度，就是说它不能正确的反应鱼群深度信息。当同样数量和分布的鱼，距离比相机远所生成密度图就会比距离近所生成的密度图要密集得多。</li>
<li>因此当鱼群上游到水的表面，或者养殖的水比较浅时，这时候的密度图才能最有效反应鱼群的分布情况。</li>
<li>还有一篇论文，对网箱离的鱼使用普通相机进行拍摄计数，精度不错，模型是将前两篇论文的模型拼起来。如果加上第三篇论文的 self supervised learning，也许精度会更高。</li>
</ul>
<footer>Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021</footer>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="45" data-paginate="true" data-header="3. Learning tools sharing" data-footer="Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021" data-theme="default" data-marpit-pagination="45" data-marpit-pagination-total="56" style="--paginate:true;--header:3. Learning tools sharing;--footer:Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021;--theme:default;">
<header>3. Learning tools sharing</header>

<h1 id="3-learning-tools-sharing">3. Learning tools sharing</h1>
<footer>Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021</footer>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="46" data-paginate="true" data-header="3. Learning tools sharing" data-footer="Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021" data-theme="default" data-marpit-pagination="46" data-marpit-pagination-total="56" style="--paginate:true;--header:3. Learning tools sharing;--footer:Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021;--theme:default;">
<header>3. Learning tools sharing</header>
<h2 id="31-ssh">3.1. SSH</h2>
<p>SSH（Secure Shell）是一种网络通信协议，它使两台计算机能够进行通信（与 http 不同，后者是用于传输超文本，如 web pages）。SSH 的一个内在特性是，两台计算机之间的通信是加密的，这意味着它适用于不安全的网络环境。</p>
<p>ssh 有主意这几个特性:</p>
<ul>
<li>Connecting to a remote host.</li>
<li>Backing up, copying, and mirroring files using SFTP.</li>
<li>Mapping a client's port to the server's port to secure TCP/IP and other network protocols.</li>
</ul>
<footer>Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021</footer>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="47" data-paginate="true" data-header="3. Learning tools sharing" data-footer="Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021" data-theme="default" data-marpit-pagination="47" data-marpit-pagination-total="56" style="--paginate:true;--header:3. Learning tools sharing;--footer:Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021;--theme:default;">
<header>3. Learning tools sharing</header>
<p>ssh 来连接远程服务器与我们所理解的远程控制电脑不一样。远程控制使用的是远程桌面协议（Remote Desktop Protocol，RDP），它是用于远程控制 Windows 计算机的协议，允许用户在远程计算机上查看和操作桌面界面。</p>
<p>一个电脑被远程控制后，其他人是无法继续控制这台电脑的，但是使用 ssh 协议来连接远程电脑，是可以允许多个人控制同一台电脑。</p>
<p>在终端中输入如下命令，就可以范围远程服务器。换句话理解就是你控制的远程服务器的终端</p>
<pre is="marp-pre" data-auto-scaling="downscale-only"><code class="language-powershell">ssh wu@<span class="hljs-number">172.18</span>.<span class="hljs-number">137.178</span>
</code></pre>
<footer>Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021</footer>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="48" data-paginate="true" data-header="3. Learning tools sharing" data-footer="Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021" data-theme="default" data-marpit-pagination="48" data-marpit-pagination-total="56" style="--paginate:true;--header:3. Learning tools sharing;--footer:Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021;--theme:default;">
<header>3. Learning tools sharing</header>
<p>因为任何编程语言的运行，本质都是通过终端的一个命令来执行，例如 python 代码的运行就是：</p>
<pre is="marp-pre" data-auto-scaling="downscale-only"><code class="language-powershell">python your_file.py
</code></pre>
<p>也就是说你控制服务器的终端，就意味着基本可以控制服务器上所有资源，例如服务器上的 python 解释器。这样就使得你可以自己的电脑写代码，但是使用的是服务器上的资源运行代码，就好像在自己电脑运行上一样。</p>
<blockquote>
<p>VSCode，Pycharm 等现在代码编辑器都支持了以 SSH 的方式连接服务器</p>
</blockquote>
<footer>Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021</footer>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="49" data-paginate="true" data-header="3. Learning tools sharing" data-footer="Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021" data-theme="default" data-marpit-pagination="49" data-marpit-pagination-total="56" style="--paginate:true;--header:3. Learning tools sharing;--footer:Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021;--theme:default;">
<header>3. Learning tools sharing</header>
<h2 id="32-conda">3.2 Conda</h2>
<p>现在大多数人使用 python 编程时，基本都会使用 Conda 来对 python 进行管理。conda 可以很方便的升级 python 包，切换 python 环境。</p>
<p>conda 的 Distribution 目前有如下几个</p>
<ol>
<li><strong>Anaconda</strong>: 是一个公司的产品，由公司来主导。商用付费，个人暂时免费，最臃肿的 conda 发行版本，因为安装 anaconda 后会安装很多额外的包，并且还包括一个没什么用图形化界面，不推荐使用。</li>
<li><strong>Miniconda</strong>: miniconda 和 anaconda 是来自于同一个公司的，也是由公司来主导的。它使用<code>anaconda.org</code>作为默认 channel。它是 Anaconda 轻量版，没有图像画界面，所占空间很小。</li>
<li><strong>Miniforge</strong>: 由社区主导，由 GitHub 托管，完全免费。与 miniconda 一样，是 anaconda 轻量版，默认 channel 为<code>conda-forge</code>，目前主流的安装 conda 的渠道就是<code>conda-forge</code>所占空间很小，不包括可视化界面，推荐使用。</li>
</ol>
<footer>Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021</footer>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="50" data-paginate="true" data-header="3. Learning tools sharing" data-footer="Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021" data-theme="default" data-marpit-pagination="50" data-marpit-pagination-total="56" style="--paginate:true;--header:3. Learning tools sharing;--footer:Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021;--theme:default;">
<header>3. Learning tools sharing</header>
<h3 id="321-mamba">3.2.1 Mamba</h3>
<p>除了以上三种发行版本，python 还有一种包管理工具在 Mamba，这个 Mamba 和 conda 基本差不多。Mamba 也有几个 Distribution:</p>
<ol>
<li><strong>Mambaforge</strong>: conda 的一种替代品，由 C++实现的，并且提供并行计算技术，使得安装 python 包时非常快,默认 channel 为<code>conda-forge</code>。使用 Mamba 的话，安装指令是<code>mamba install</code>而不是<code>conda install</code></li>
<li><strong>Micromamba</strong>: Micromamba 是 Mambaforge 非常小的版本，他拥有 Mambaforge 所有的特性，但是最重要的是，它剔除了 base 环境，因为 base 环境基本所有人都不会去使用，所以没必要保留</li>
</ol>
<footer>Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021</footer>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="51" data-paginate="true" data-header="3. Learning tools sharing" data-footer="Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021" data-theme="default" data-marpit-pagination="51" data-marpit-pagination-total="56" style="--paginate:true;--header:3. Learning tools sharing;--footer:Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021;--theme:default;">
<header>3. Learning tools sharing</header>
<h2 id="33-git">3.3 Git</h2>
<p>git 是用来管理项目的工具，是一个开源的分布式版本控制系统。使用 git 来管理你的代码项目，你可以将项目切换到任意时间点，而不用担心因为代码保存而覆盖掉之的版本</p>
<p><img src="./image/git%20version%20switch.png" alt="" /></p>
<footer>Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021</footer>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section data-paginate="true" data-header="3. Learning tools sharing" data-footer="Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021" data-theme="default" data-marpit-pagination="52" data-marpit-pagination-total="56" style="--paginate:true;--header:3. Learning tools sharing;--footer:Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021;--theme:default;--marpit-advanced-background-split:50%;" data-marpit-advanced-background="background" data-marpit-advanced-background-split="right"><div data-marpit-advanced-background-container="true" data-marpit-advanced-background-direction="horizontal"><figure style="background-image:url(&quot;./image/git%20pull.png&quot;);background-size:auto 4in;"></figure></div></section></foreignObject><foreignObject width="50%" height="720"><section id="52" data-paginate="true" data-header="3. Learning tools sharing" data-footer="Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021" data-theme="default" data-marpit-pagination="52" data-marpit-pagination-total="56" style="--paginate:true;--header:3. Learning tools sharing;--footer:Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021;--theme:default;--marpit-advanced-background-split:50%;" data-marpit-advanced-background="content" data-marpit-advanced-background-split="right">
<header>3. Learning tools sharing</header>
<p>git 最有用的方式还是配合 Github 一起使用，当在 Github 上发现有用的代码时，应该使用 git，通过 ssh 协议将代码拉下来，而不是使用下载的方式下载下来,这样拉下来的项目才能被 git 管理，而且不用解压，而下载下来的文件需要解压。</p>
<pre is="marp-pre" data-auto-scaling="downscale-only"><code class="language-shell">git clone git@github.com:ptarling/DeepLearningFishCounting.git
</code></pre>
<footer>Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021</footer>
</section>
</foreignObject><foreignObject width="1280" height="720" data-marpit-advanced-background="pseudo"><section data-paginate="true" data-header="3. Learning tools sharing" data-footer="Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021" data-theme="default" data-marpit-pagination="52" data-marpit-pagination-total="56" style="" data-marpit-advanced-background="pseudo" data-marpit-advanced-background-split="right"></section></foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="53" data-paginate="true" data-header="3. Learning tools sharing" data-footer="Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021" data-theme="default" data-marpit-pagination="53" data-marpit-pagination-total="56" style="--paginate:true;--header:3. Learning tools sharing;--footer:Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021;--theme:default;">
<header>3. Learning tools sharing</header>
<h2 id="34-github">3.4. Github</h2>
<p>Github 是全球最大的代码托管平台，全世界有很多为爱发电的人，把自己做的东西上传到 github 上，供所有人使用，例如上文提到的<code>Miniforge</code>等。只有被 git 管理的项目才能上传在 Github 上。Github 可以算类似一个免费的云，可以在上面存放任何代码，并且没有限制，所以越来越多的开发者以及论文作者，会把代码放在 Github 上。放在 Github 上的代码可以被任何人浏览，如果有人喜欢你的项目，就会阅读你的代码，还可能给你的代码提出修改意见。可以通过<code>pull requests</code>的方式，给别人的开源代码提出修改，如果作者同意你的修改的话，你就会成为他代码的贡献者。</p>
<footer>Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021</footer>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section data-paginate="true" data-header="3. Learning tools sharing" data-footer="Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021" data-theme="default" data-marpit-pagination="54" data-marpit-pagination-total="56" style="--paginate:true;--header:3. Learning tools sharing;--footer:Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021;--theme:default;--marpit-advanced-background-split:50%;" data-marpit-advanced-background="background" data-marpit-advanced-background-split="right"><div data-marpit-advanced-background-container="true" data-marpit-advanced-background-direction="horizontal"><figure style="background-image:url(&quot;./image/issues.png&quot;);background-size:auto 5in;"></figure></div></section></foreignObject><foreignObject width="50%" height="720"><section id="54" data-paginate="true" data-header="3. Learning tools sharing" data-footer="Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021" data-theme="default" data-marpit-pagination="54" data-marpit-pagination-total="56" style="--paginate:true;--header:3. Learning tools sharing;--footer:Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021;--theme:default;--marpit-advanced-background-split:50%;" data-marpit-advanced-background="content" data-marpit-advanced-background-split="right">
<header>3. Learning tools sharing</header>
<p>例如我在阅读 fish counting 那篇论文，我发现它的论文以及代码有问题，所以我在作者的 Github 上提出了 issue，作者回复说很感谢我的提问，并且联系论文的通讯作者来解答我的问题。</p>

<p><img src="./image/author%20response.png" alt="" /></p>
<footer>Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021</footer>
</section>
</foreignObject><foreignObject width="1280" height="720" data-marpit-advanced-background="pseudo"><section data-paginate="true" data-header="3. Learning tools sharing" data-footer="Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021" data-theme="default" data-marpit-pagination="54" data-marpit-pagination-total="56" style="" data-marpit-advanced-background="pseudo" data-marpit-advanced-background-split="right"></section></foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section id="55" data-paginate="true" data-header="3. Learning tools sharing" data-footer="Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021" data-theme="default" data-marpit-pagination="55" data-marpit-pagination-total="56" style="--paginate:true;--header:3. Learning tools sharing;--footer:Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021;--theme:default;">
<header>3. Learning tools sharing</header>
<p>这篇 fish counting 所开放的代码也有很多我无法理解的点和 bug，并且代码缺失了部分文件，例如如何将视频转换为图片帧，我修改了部分代码，并且补充了一些代码文件。我提交了我的 pull requests，如果作者同意我的 PR，那么我代码也会合并他的代码里，成为代码的贡献者之一。</p>
<footer>Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021</footer>
</section>
</foreignObject></svg><svg data-marpit-svg="" viewBox="0 0 1280 720"><foreignObject width="1280" height="720"><section data-paginate="true" data-header="3. Learning tools sharing" data-footer="Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021" data-theme="default" data-marpit-pagination="56" data-marpit-pagination-total="56" style="--paginate:true;--header:3. Learning tools sharing;--footer:Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021;--theme:default;" data-marpit-advanced-background="background"><div data-marpit-advanced-background-container="true" data-marpit-advanced-background-direction="horizontal"><figure style="background-image:url(&quot;./image/pull%20requests.png&quot;);"></figure></div></section></foreignObject><foreignObject width="1280" height="720"><section id="56" data-paginate="true" data-header="3. Learning tools sharing" data-footer="Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021" data-theme="default" data-marpit-pagination="56" data-marpit-pagination-total="56" style="--paginate:true;--header:3. Learning tools sharing;--footer:Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021;--theme:default;" data-marpit-advanced-background="content">
<header>3. Learning tools sharing</header>
<footer>Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021</footer>
</section>
<script>!function(){"use strict";const t={h1:{proto:()=>HTMLHeadingElement,attrs:{role:"heading","aria-level":"1"},style:"display: block; font-size: 2em; margin-block-start: 0.67em; margin-block-end: 0.67em; margin-inline-start: 0px; margin-inline-end: 0px; font-weight: bold;"},h2:{proto:()=>HTMLHeadingElement,attrs:{role:"heading","aria-level":"2"},style:"display: block; font-size: 1.5em; margin-block-start: 0.83em; margin-block-end: 0.83em; margin-inline-start: 0px; margin-inline-end: 0px; font-weight: bold;"},h3:{proto:()=>HTMLHeadingElement,attrs:{role:"heading","aria-level":"3"},style:"display: block; font-size: 1.17em; margin-block-start: 1em; margin-block-end: 1em; margin-inline-start: 0px; margin-inline-end: 0px; font-weight: bold;"},h4:{proto:()=>HTMLHeadingElement,attrs:{role:"heading","aria-level":"4"},style:"display: block; margin-block-start: 1.33em; margin-block-end: 1.33em; margin-inline-start: 0px; margin-inline-end: 0px; font-weight: bold;"},h5:{proto:()=>HTMLHeadingElement,attrs:{role:"heading","aria-level":"5"},style:"display: block; font-size: 0.83em; margin-block-start: 1.67em; margin-block-end: 1.67em; margin-inline-start: 0px; margin-inline-end: 0px; font-weight: bold;"},h6:{proto:()=>HTMLHeadingElement,attrs:{role:"heading","aria-level":"6"},style:"display: block; font-size: 0.67em; margin-block-start: 2.33em; margin-block-end: 2.33em; margin-inline-start: 0px; margin-inline-end: 0px; font-weight: bold;"},span:{proto:()=>HTMLSpanElement},pre:{proto:()=>HTMLElement,style:"display: block; font-family: monospace; white-space: pre; margin: 1em 0; --marp-auto-scaling-white-space: pre;"}},e="data-marp-auto-scaling-wrapper",i="data-marp-auto-scaling-svg",n="data-marp-auto-scaling-container";class s extends HTMLElement{constructor(){super(),this.svgPreserveAspectRatio="xMinYMid meet";const t=t=>([e])=>{const{width:i,height:n}=e.contentRect;this[t]={width:i,height:n},this.updateSVGRect()};this.attachShadow({mode:"open"}),this.containerObserver=new ResizeObserver(t("containerSize")),this.wrapperObserver=new ResizeObserver(((...e)=>{t("wrapperSize")(...e),this.flushSvgDisplay()}))}static get observedAttributes(){return["data-downscale-only"]}connectedCallback(){var t,s,o,r,a;this.shadowRoot.innerHTML=`\n<style>\n  svg[${i}] { display: block; width: 100%; height: auto; vertical-align: top; }\n  span[${n}] { display: table; white-space: var(--marp-auto-scaling-white-space, nowrap); width: max-content; }\n</style>\n<div ${e}>\n  <svg part="svg" ${i}>\n    <foreignObject><span ${n}><slot></slot></span></foreignObject>\n  </svg>\n</div>\n    `.split(/\n\s*/).join(""),this.wrapper=null!==(t=this.shadowRoot.querySelector(`div[${e}]`))&&void 0!==t?t:void 0;const l=this.svg;this.svg=null!==(o=null===(s=this.wrapper)||void 0===s?void 0:s.querySelector(`svg[${i}]`))&&void 0!==o?o:void 0,this.svg!==l&&(this.svgComputedStyle=this.svg?window.getComputedStyle(this.svg):void 0),this.container=null!==(a=null===(r=this.svg)||void 0===r?void 0:r.querySelector(`span[${n}]`))&&void 0!==a?a:void 0,this.observe()}disconnectedCallback(){this.svg=void 0,this.svgComputedStyle=void 0,this.wrapper=void 0,this.container=void 0,this.observe()}attributeChangedCallback(){this.observe()}flushSvgDisplay(){const{svg:t}=this;t&&(t.style.display="inline",requestAnimationFrame((()=>{t.style.display=""})))}observe(){this.containerObserver.disconnect(),this.wrapperObserver.disconnect(),this.wrapper&&this.wrapperObserver.observe(this.wrapper),this.container&&this.containerObserver.observe(this.container),this.svgComputedStyle&&this.observeSVGStyle(this.svgComputedStyle)}observeSVGStyle(t){const e=()=>{const i=(()=>{const e=t.getPropertyValue("--preserve-aspect-ratio");if(e)return e.trim();return`x${(({textAlign:t,direction:e})=>{if(t.endsWith("left"))return"Min";if(t.endsWith("right"))return"Max";if("start"===t||"end"===t){let i="rtl"===e;return"end"===t&&(i=!i),i?"Max":"Min"}return"Mid"})(t)}YMid meet`})();i!==this.svgPreserveAspectRatio&&(this.svgPreserveAspectRatio=i,this.updateSVGRect()),t===this.svgComputedStyle&&requestAnimationFrame(e)};e()}updateSVGRect(){var t,e,i,n,s,o,r;let a=Math.ceil(null!==(e=null===(t=this.containerSize)||void 0===t?void 0:t.width)&&void 0!==e?e:0);const l=Math.ceil(null!==(n=null===(i=this.containerSize)||void 0===i?void 0:i.height)&&void 0!==n?n:0);void 0!==this.dataset.downscaleOnly&&(a=Math.max(a,null!==(o=null===(s=this.wrapperSize)||void 0===s?void 0:s.width)&&void 0!==o?o:0));const c=null===(r=this.svg)||void 0===r?void 0:r.querySelector(":scope > foreignObject");if(null==c||c.setAttribute("width",`${a}`),null==c||c.setAttribute("height",`${l}`),this.svg&&(this.svg.setAttribute("viewBox",`0 0 ${a} ${l}`),this.svg.setAttribute("preserveAspectRatio",this.svgPreserveAspectRatio),this.svg.style.height=a<=0||l<=0?"0":""),this.container){const t=this.svgPreserveAspectRatio.toLowerCase();this.container.style.marginLeft=t.startsWith("xmid")||t.startsWith("xmax")?"auto":"0",this.container.style.marginRight=t.startsWith("xmi")?"auto":"0"}}}const o=(t,{attrs:e={},style:i})=>class extends t{constructor(...t){super(...t);for(const[t,i]of Object.entries(e))this.hasAttribute(t)||this.setAttribute(t,i);this.attachShadow({mode:"open"})}static get observedAttributes(){return["data-auto-scaling"]}connectedCallback(){this._update()}attributeChangedCallback(){this._update()}_update(){const t=i?`<style>:host { ${i} }</style>`:"";let e="<slot></slot>";const{autoScaling:n}=this.dataset;if(void 0!==n){e=`<marp-auto-scaling exportparts="svg:auto-scaling" ${"downscale-only"===n?"data-downscale-only":""}>${e}</marp-auto-scaling>`}this.shadowRoot.innerHTML=t+e}};let r;const a=Symbol();let l;const c="marpitSVGPolyfill:setZoomFactor,",d=Symbol(),g=Symbol();const h=()=>{const t="Apple Computer, Inc."===navigator.vendor,e=t?[u]:[],i={then:e=>(t?(async()=>{if(void 0===l){const t=document.createElement("canvas");t.width=10,t.height=10;const e=t.getContext("2d"),i=new Image(10,10),n=new Promise((t=>{i.addEventListener("load",(()=>t()))}));i.crossOrigin="anonymous",i.src="data:image/svg+xml;charset=utf8,%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20width%3D%2210%22%20height%3D%2210%22%20viewBox%3D%220%200%201%201%22%3E%3CforeignObject%20width%3D%221%22%20height%3D%221%22%20requiredExtensions%3D%22http%3A%2F%2Fwww.w3.org%2F1999%2Fxhtml%22%3E%3Cdiv%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F1999%2Fxhtml%22%20style%3D%22width%3A%201px%3B%20height%3A%201px%3B%20background%3A%20red%3B%20position%3A%20relative%22%3E%3C%2Fdiv%3E%3C%2FforeignObject%3E%3C%2Fsvg%3E",await n,e.drawImage(i,0,0),l=e.getImageData(5,5,1,1).data[3]<128}return l})().then((t=>{null==e||e(t?[u]:[])})):null==e||e([]),i)};return Object.assign(e,i)};let p,m;function u(t){const e="object"==typeof t&&t.target||document,i="object"==typeof t?t.zoom:t;window[g]||(Object.defineProperty(window,g,{configurable:!0,value:!0}),document.body.style.zoom=1.0001,document.body.offsetHeight,document.body.style.zoom=1,window.addEventListener("message",(({data:t,origin:e})=>{if(e===window.origin)try{if(t&&"string"==typeof t&&t.startsWith(c)){const[,e]=t.split(","),i=Number.parseFloat(e);Number.isNaN(i)||(m=i)}}catch(t){console.error(t)}})));let n=!1;Array.from(e.querySelectorAll("svg[data-marpit-svg]"),(t=>{var e,s,o,r;t.style.transform||(t.style.transform="translateZ(0)");const a=i||m||t.currentScale||1;p!==a&&(p=a,n=a);const l=t.getBoundingClientRect(),{length:c}=t.children;for(let i=0;i<c;i+=1){const n=t.children[i];if(n.getScreenCTM){const t=n.getScreenCTM();if(t){const i=null!==(s=null===(e=n.x)||void 0===e?void 0:e.baseVal.value)&&void 0!==s?s:0,c=null!==(r=null===(o=n.y)||void 0===o?void 0:o.baseVal.value)&&void 0!==r?r:0,d=n.children.length;for(let e=0;e<d;e+=1){const s=n.children[e];if("SECTION"===s.tagName){const{style:e}=s;e.transformOrigin||(e.transformOrigin=`${-i}px ${-c}px`),e.transform=`scale(${a}) matrix(${t.a}, ${t.b}, ${t.c}, ${t.d}, ${t.e-l.left}, ${t.f-l.top}) translateZ(0.0001px)`;break}}}}}})),!1!==n&&Array.from(e.querySelectorAll("iframe"),(({contentWindow:t})=>{null==t||t.postMessage(`${c}${n}`,"null"===window.origin?"*":window.origin)}))}function v({once:t=!1,target:e=document}={}){const i=function(t=document){if(t[d])return t[d];let e=!0;const i=()=>{e=!1,delete t[d]};Object.defineProperty(t,d,{configurable:!0,value:i});let n=[],s=!1;(async()=>{try{n=await h()}finally{s=!0}})();const o=()=>{for(const e of n)e({target:t});s&&0===n.length||e&&window.requestAnimationFrame(o)};return o(),i}(e);return t?(i(),()=>{}):i}p=1,m=void 0;const b=Symbol(),w=(e=document)=>{if("undefined"==typeof window)throw new Error("Marp Core's browser script is valid only in browser context.");if(((e=document)=>{const i=window[a];i||customElements.define("marp-auto-scaling",s);for(const n of Object.keys(t)){const s=`marp-${n}`,a=t[n].proto();null!=r||(r=!!document.createElement("div",{is:"marp-auto-scaling"}).outerHTML.startsWith("<div is")),r&&a!==HTMLElement?i||customElements.define(s,o(a,{style:t[n].style}),{extends:n}):(i||customElements.define(s,o(HTMLElement,t[n])),e.querySelectorAll(`${n}[is="${s}"]`).forEach((t=>{t.outerHTML=t.outerHTML.replace(new RegExp(`^<${n}`,"i"),`<${s}`).replace(new RegExp(`</${n}>$`,"i"),`</${s}>`)})))}window[a]=!0})(e),e[b])return e[b];const i=v({target:e}),n=()=>{i(),delete e[b]},l=Object.assign(n,{cleanup:n,update:()=>w(e)});return Object.defineProperty(e,b,{configurable:!0,value:l}),l},y=document.currentScript;w(y?y.getRootNode():document)}();
</script></foreignObject><foreignObject width="1280" height="720" data-marpit-advanced-background="pseudo"><section data-paginate="true" data-header="3. Learning tools sharing" data-footer="Deep learning with self-supervision and uncertainty regularization to count fish in underwater images-CVPR 2021" data-theme="default" data-marpit-pagination="56" data-marpit-pagination-total="56" style="" data-marpit-advanced-background="pseudo"></section></foreignObject></svg></div><script>/*!! License: https://unpkg.com/@marp-team/marp-cli@3.2.0/lib/bespoke.js.LICENSE.txt */
!function(){"use strict";function e(e){return e&&e.__esModule&&Object.prototype.hasOwnProperty.call(e,"default")?e.default:e}var t={from:function(e,t){var n,r=1===(e.parent||e).nodeType?e.parent||e:document.querySelector(e.parent||e),o=[].filter.call("string"==typeof e.slides?r.querySelectorAll(e.slides):e.slides||r.children,(function(e){return"SCRIPT"!==e.nodeName})),i={},a=function(e,t){return(t=t||{}).index=o.indexOf(e),t.slide=e,t},s=function(e,t){i[e]=(i[e]||[]).filter((function(e){return e!==t}))},l=function(e,t){return(i[e]||[]).reduce((function(e,n){return e&&!1!==n(t)}),!0)},c=function(e,t){o[e]&&(n&&l("deactivate",a(n,t)),n=o[e],l("activate",a(n,t)))},d=function(e,t){var r=o.indexOf(n)+e;l(e>0?"next":"prev",a(n,t))&&c(r,t)},u={off:s,on:function(e,t){return(i[e]||(i[e]=[])).push(t),s.bind(null,e,t)},fire:l,slide:function(e,t){if(!arguments.length)return o.indexOf(n);l("slide",a(o[e],t))&&c(e,t)},next:d.bind(null,1),prev:d.bind(null,-1),parent:r,slides:o,destroy:function(e){l("destroy",a(n,e)),i={}}};return(t||[]).forEach((function(e){e(u)})),n||c(0),u}},n=e(t);const r=document.body,o=(...e)=>history.replaceState(...e),i="presenter",a="next",s=["",i,a],l="bespoke-marp-",c=`data-${l}`,d=(e,{protocol:t,host:n,pathname:r,hash:o}=location)=>{const i=e.toString();return`${t}//${n}${r}${i?"?":""}${i}${o}`},u=()=>r.dataset.bespokeView,f=e=>new URLSearchParams(location.search).get(e),m=(e,t={})=>{var n;const r={location,setter:o,...t},i=new URLSearchParams(r.location.search);for(const t of Object.keys(e)){const n=e[t];"string"==typeof n?i.set(t,n):i.delete(t)}try{r.setter({...null!==(n=window.history.state)&&void 0!==n?n:{}},"",d(i,r.location))}catch(e){console.error(e)}},g=(()=>{const e="bespoke-marp";try{return localStorage.setItem(e,e),localStorage.removeItem(e),!0}catch(e){return!1}})(),p=e=>{try{return localStorage.getItem(e)}catch(e){return null}},v=(e,t)=>{try{return localStorage.setItem(e,t),!0}catch(e){return!1}},h=e=>{try{return localStorage.removeItem(e),!0}catch(e){return!1}},y=(e,t)=>{const n="aria-hidden";t?e.setAttribute(n,"true"):e.removeAttribute(n)},b=e=>{e.parent.classList.add(`${l}parent`),e.slides.forEach((e=>e.classList.add(`${l}slide`))),e.on("activate",(t=>{const n=`${l}active`,r=t.slide,o=r.classList,i=!o.contains(n);if(e.slides.forEach((e=>{e.classList.remove(n),y(e,!0)})),o.add(n),y(r,!1),i){const e=`${n}-ready`;o.add(e),document.body.clientHeight,o.remove(e)}}))},w=e=>{let t=0,n=0;Object.defineProperty(e,"fragments",{enumerable:!0,value:e.slides.map((e=>[null,...e.querySelectorAll("[data-marpit-fragment]")]))});const r=r=>void 0!==e.fragments[t][n+r],o=(r,o)=>{t=r,n=o,e.fragments.forEach(((e,t)=>{e.forEach(((e,n)=>{if(null==e)return;const i=t<r||t===r&&n<=o;e.setAttribute(`${c}fragment`,(i?"":"in")+"active");const a=`${c}current-fragment`;t===r&&n===o?e.setAttribute(a,"current"):e.removeAttribute(a)}))})),e.fragmentIndex=o;const i={slide:e.slides[r],index:r,fragments:e.fragments[r],fragmentIndex:o};e.fire("fragment",i)};e.on("next",(({fragment:i=!0})=>{if(i){if(r(1))return o(t,n+1),!1;const i=t+1;e.fragments[i]&&o(i,0)}else{const r=e.fragments[t].length;if(n+1<r)return o(t,r-1),!1;const i=e.fragments[t+1];i&&o(t+1,i.length-1)}})),e.on("prev",(({fragment:i=!0})=>{if(r(-1)&&i)return o(t,n-1),!1;const a=t-1;e.fragments[a]&&o(a,e.fragments[a].length-1)})),e.on("slide",(({index:t,fragment:n})=>{let r=0;if(void 0!==n){const o=e.fragments[t];if(o){const{length:e}=o;r=-1===n?e-1:Math.min(Math.max(n,0),e-1)}}o(t,r)})),o(0,0)},x=document,k=()=>!(!x.fullscreenEnabled&&!x.webkitFullscreenEnabled),$=()=>!(!x.fullscreenElement&&!x.webkitFullscreenElement),E=e=>{e.fullscreen=()=>{k()&&(async()=>{return $()?null===(e=x.exitFullscreen||x.webkitExitFullscreen)||void 0===e?void 0:e.call(x):((e=x.body)=>{var t;return null===(t=e.requestFullscreen||e.webkitRequestFullscreen)||void 0===t?void 0:t.call(e)})();var e})()},document.addEventListener("keydown",(t=>{"f"!==t.key&&"F11"!==t.key||t.altKey||t.ctrlKey||t.metaKey||!k()||(e.fullscreen(),t.preventDefault())}))},L=`${l}inactive`,S=(e=2e3)=>({parent:t,fire:n})=>{const r=t.classList,o=e=>n(`marp-${e?"":"in"}active`);let i;const a=()=>{i&&clearTimeout(i),i=setTimeout((()=>{r.add(L),o()}),e),r.contains(L)&&(r.remove(L),o(!0))};for(const e of["mousedown","mousemove","touchend"])document.addEventListener(e,a);setTimeout(a,0)},P=["AUDIO","BUTTON","INPUT","SELECT","TEXTAREA","VIDEO"],_=e=>{e.parent.addEventListener("keydown",(e=>{if(!e.target)return;const t=e.target;(P.includes(t.nodeName)||"true"===t.contentEditable)&&e.stopPropagation()}))},T=e=>{window.addEventListener("load",(()=>{for(const t of e.slides){const e=t.querySelector("marp-auto-scaling, [data-auto-scaling], [data-marp-fitting]");t.setAttribute(`${c}load`,e?"":"hideable")}}))},I=({interval:e=250}={})=>t=>{document.addEventListener("keydown",(e=>{if(" "===e.key&&e.shiftKey)t.prev();else if("ArrowLeft"===e.key||"ArrowUp"===e.key||"PageUp"===e.key)t.prev({fragment:!e.shiftKey});else if(" "!==e.key||e.shiftKey)if("ArrowRight"===e.key||"ArrowDown"===e.key||"PageDown"===e.key)t.next({fragment:!e.shiftKey});else if("End"===e.key)t.slide(t.slides.length-1,{fragment:-1});else{if("Home"!==e.key)return;t.slide(0)}else t.next();e.preventDefault()}));let n,r,o=0;t.parent.addEventListener("wheel",(i=>{let a=!1;const s=(e,t)=>{e&&(a=a||((e,t)=>((e,t)=>{const n="X"===t?"Width":"Height";return e[`client${n}`]<e[`scroll${n}`]})(e,t)&&((e,t)=>{const{overflow:n}=e,r=e[`overflow${t}`];return"auto"===n||"scroll"===n||"auto"===r||"scroll"===r})(getComputedStyle(e),t))(e,t)),(null==e?void 0:e.parentElement)&&s(e.parentElement,t)};if(0!==i.deltaX&&s(i.target,"X"),0!==i.deltaY&&s(i.target,"Y"),a)return;i.preventDefault();const l=Math.sqrt(i.deltaX**2+i.deltaY**2);if(void 0!==i.wheelDelta){if(void 0===i.webkitForce&&Math.abs(i.wheelDelta)<40)return;if(i.deltaMode===i.DOM_DELTA_PIXEL&&l<4)return}else if(i.deltaMode===i.DOM_DELTA_PIXEL&&l<12)return;r&&clearTimeout(r),r=setTimeout((()=>{n=0}),e);const c=Date.now()-o<e,d=l<=n;if(n=l,c||d)return;let u;(i.deltaX>0||i.deltaY>0)&&(u="next"),(i.deltaX<0||i.deltaY<0)&&(u="prev"),u&&(t[u](),o=Date.now())}))},M=(e=`.${l}osc`)=>{const t=document.querySelector(e);if(!t)return()=>{};const n=(e,n)=>{t.querySelectorAll(`[${c}osc=${JSON.stringify(e)}]`).forEach(n)};return k()||n("fullscreen",(e=>e.style.display="none")),g||n("presenter",(e=>{e.disabled=!0,e.title="Presenter view is disabled due to restricted localStorage."})),e=>{t.addEventListener("click",(t=>{if(t.target instanceof HTMLElement){const{bespokeMarpOsc:n}=t.target.dataset;n&&t.target.blur();const r={fragment:!t.shiftKey};"next"===n?e.next(r):"prev"===n?e.prev(r):"fullscreen"===n?null==e||e.fullscreen():"presenter"===n&&e.openPresenterView()}})),e.parent.appendChild(t),e.on("activate",(({index:t})=>{n("page",(n=>n.textContent=`Page ${t+1} of ${e.slides.length}`))})),e.on("fragment",(({index:t,fragments:r,fragmentIndex:o})=>{n("prev",(e=>e.disabled=0===t&&0===o)),n("next",(n=>n.disabled=t===e.slides.length-1&&o===r.length-1))})),e.on("marp-active",(()=>y(t,!1))),e.on("marp-inactive",(()=>y(t,!0))),k()&&(e=>{for(const t of["","webkit"])x.addEventListener(t+"fullscreenchange",e)})((()=>n("fullscreen",(e=>e.classList.toggle("exit",k()&&$())))))}},O=e=>{window.addEventListener("message",(t=>{if(t.origin!==window.origin)return;const[n,r]=t.data.split(":");if("navigate"===n){const[t,n]=r.split(",");let o=Number.parseInt(t,10),i=Number.parseInt(n,10)+1;i>=e.fragments[o].length&&(o+=1,i=0),e.slide(o,{fragment:i})}}))};var A=["area","base","br","col","command","embed","hr","img","input","keygen","link","meta","param","source","track","wbr"];let C=e=>String(e).replace(/[&<>"']/g,(e=>`&${D[e]};`)),D={"&":"amp","<":"lt",">":"gt",'"':"quot","'":"apos"},N="dangerouslySetInnerHTML",B={className:"class",htmlFor:"for"},q={};function K(e,t){let n=[],r="";t=t||{};for(let e=arguments.length;e-- >2;)n.push(arguments[e]);if("function"==typeof e)return t.children=n.reverse(),e(t);if(e){if(r+="<"+e,t)for(let e in t)!1!==t[e]&&null!=t[e]&&e!==N&&(r+=` ${B[e]?B[e]:C(e)}="${C(t[e])}"`);r+=">"}if(-1===A.indexOf(e)){if(t[N])r+=t[N].__html;else for(;n.length;){let e=n.pop();if(e)if(e.pop)for(let t=e.length;t--;)n.push(e[t]);else r+=!0===q[e]?e:C(e)}r+=e?`</${e}>`:""}return q[r]=!0,r}const j=({children:e})=>K(null,null,...e),F=`${l}presenter-`,V={container:`${F}container`,dragbar:`${F}dragbar-container`,next:`${F}next`,nextContainer:`${F}next-container`,noteContainer:`${F}note-container`,noteWrapper:`${F}note-wrapper`,noteButtons:`${F}note-buttons`,infoContainer:`${F}info-container`,infoPage:`${F}info-page`,infoPageText:`${F}info-page-text`,infoPagePrev:`${F}info-page-prev`,infoPageNext:`${F}info-page-next`,noteButtonsBigger:`${F}note-bigger`,noteButtonsSmaller:`${F}note-smaller`,infoTime:`${F}info-time`,infoTimer:`${F}info-timer`},U=e=>{const{title:t}=document;document.title="[Presenter view]"+(t?` - ${t}`:"");const n={},r=e=>(n[e]=n[e]||document.querySelector(`.${e}`),n[e]);document.body.appendChild((e=>{const t=document.createElement("div");return t.className=V.container,t.appendChild(e),t.insertAdjacentHTML("beforeend",K(j,null,K("div",{class:V.nextContainer},K("iframe",{class:V.next,src:"?view=next"})),K("div",{class:V.dragbar}),K("div",{class:V.noteContainer},K("div",{class:V.noteWrapper}),K("div",{class:V.noteButtons},K("button",{class:V.noteButtonsSmaller,tabindex:"-1",title:"Smaller notes font size"},"Smaller notes font size"),K("button",{class:V.noteButtonsBigger,tabindex:"-1",title:"Bigger notes font size"},"Bigger notes font size"))),K("div",{class:V.infoContainer},K("div",{class:V.infoPage},K("button",{class:V.infoPagePrev,tabindex:"-1",title:"Previous"},"Previous"),K("span",{class:V.infoPageText}),K("button",{class:V.infoPageNext,tabindex:"-1",title:"Next"},"Next")),K("time",{class:V.infoTime,title:"Current time"}),K("time",{class:V.infoTimer,title:"Timer"})))),t})(e.parent)),(e=>{let t=!1;r(V.dragbar).addEventListener("mousedown",(()=>{t=!0,r(V.dragbar).classList.add("active")})),window.addEventListener("mouseup",(()=>{t=!1,r(V.dragbar).classList.remove("active")})),window.addEventListener("mousemove",(e=>{if(!t)return;const n=e.clientX/document.documentElement.clientWidth*100;r(V.container).style.setProperty("--bespoke-marp-presenter-split-ratio",`${Math.max(0,Math.min(100,n))}%`)})),r(V.nextContainer).addEventListener("click",(()=>e.next()));const n=r(V.next),o=(i=n,(e,t)=>{var n;return null===(n=i.contentWindow)||void 0===n?void 0:n.postMessage(`navigate:${e},${t}`,"null"===window.origin?"*":window.origin)});var i;n.addEventListener("load",(()=>{r(V.nextContainer).classList.add("active"),o(e.slide(),e.fragmentIndex),e.on("fragment",(({index:e,fragmentIndex:t})=>o(e,t)))}));const a=document.querySelectorAll(".bespoke-marp-note");a.forEach((e=>{e.addEventListener("keydown",(e=>e.stopPropagation())),r(V.noteWrapper).appendChild(e)})),e.on("activate",(()=>a.forEach((t=>t.classList.toggle("active",t.dataset.index==e.slide())))));let s=0;const l=e=>{s=Math.max(-5,s+e),r(V.noteContainer).style.setProperty("--bespoke-marp-note-font-scale",(1.2**s).toFixed(4))},c=()=>l(1),d=()=>l(-1),u=r(V.noteButtonsBigger),f=r(V.noteButtonsSmaller);u.addEventListener("click",(()=>{u.blur(),c()})),f.addEventListener("click",(()=>{f.blur(),d()})),document.addEventListener("keydown",(e=>{"+"===e.key&&c(),"-"===e.key&&d()}),!0),e.on("activate",(({index:t})=>{r(V.infoPageText).textContent=`${t+1} / ${e.slides.length}`}));const m=r(V.infoPagePrev),g=r(V.infoPageNext);m.addEventListener("click",(t=>{m.blur(),e.prev({fragment:!t.shiftKey})})),g.addEventListener("click",(t=>{g.blur(),e.next({fragment:!t.shiftKey})})),e.on("fragment",(({index:t,fragments:n,fragmentIndex:r})=>{m.disabled=0===t&&0===r,g.disabled=t===e.slides.length-1&&r===n.length-1}));let p=new Date;const v=()=>{const e=new Date,t=e=>`${Math.floor(e)}`.padStart(2,"0"),n=e.getTime()-p.getTime(),o=t(n/1e3%60),i=t(n/1e3/60%60),a=t(n/36e5%24);r(V.infoTime).textContent=e.toLocaleTimeString(),r(V.infoTimer).textContent=`${a}:${i}:${o}`};v(),setInterval(v,250),r(V.infoTimer).addEventListener("click",(()=>{p=new Date}))})(e)},X=e=>{if(!(e=>e.syncKey&&"string"==typeof e.syncKey)(e))throw new Error("The current instance of Bespoke.js is invalid for Marp bespoke presenter plugin.");Object.defineProperties(e,{openPresenterView:{enumerable:!0,value:H},presenterUrl:{enumerable:!0,get:R}}),g&&document.addEventListener("keydown",(t=>{"p"!==t.key||t.altKey||t.ctrlKey||t.metaKey||(t.preventDefault(),e.openPresenterView())}))};function H(){const{max:e,floor:t}=Math,n=e(t(.85*window.innerWidth),640),r=e(t(.85*window.innerHeight),360);return window.open(this.presenterUrl,F+this.syncKey,`width=${n},height=${r},menubar=no,toolbar=no`)}function R(){const e=new URLSearchParams(location.search);return e.set("view","presenter"),e.set("sync",this.syncKey),d(e)}const W=e=>{const t=u();return t===a&&e.appendChild(document.createElement("span")),{"":X,[i]:U,[a]:O}[t]},J=e=>{e.on("activate",(t=>{document.querySelectorAll(".bespoke-progress-parent > .bespoke-progress-bar").forEach((n=>{n.style.flexBasis=100*t.index/(e.slides.length-1)+"%"}))}))},Y=e=>{const t=Number.parseInt(e,10);return Number.isNaN(t)?null:t},z=(e={})=>{const t={history:!0,...e};return e=>{let n=!0;const r=e=>{const t=n;try{return n=!0,e()}finally{n=t}},o=(t={fragment:!0})=>{let n=t.fragment?Y(f("f")||""):null;((t,n)=>{const{min:r,max:o}=Math,{fragments:i,slides:a}=e,s=o(0,r(t,a.length-1)),l=o(0,r(n||0,i[s].length-1));s===e.slide()&&l===e.fragmentIndex||e.slide(s,{fragment:l})})((()=>{var t,r;if(location.hash){const[o]=location.hash.slice(1).split(":~:");if(/^\d+$/.test(o))return(null!==(t=Y(o))&&void 0!==t?t:1)-1;const i=document.getElementById(o)||document.querySelector(`a[name="${CSS.escape(o)}"]`);if(i){const{length:t}=e.slides;for(let o=0;o<t;o+=1)if(e.slides[o].contains(i)){const t=null===(r=e.fragments)||void 0===r?void 0:r[o],a=i.closest("[data-marpit-fragment]");if(t&&a){const e=t.indexOf(a);e>=0&&(n=e)}return o}}}return 0})(),n)};e.on("fragment",(({index:e,fragmentIndex:r})=>{n||m({f:0===r||r.toString()},{location:{...location,hash:`#${e+1}`},setter:(...e)=>t.history?history.pushState(...e):history.replaceState(...e)})})),setTimeout((()=>{o(),window.addEventListener("hashchange",(()=>r((()=>{o({fragment:!1}),m({f:void 0})})))),window.addEventListener("popstate",(()=>{n||r((()=>o()))})),n=!1}),0)}},G=(e={})=>{var t;const n=e.key||(null===(t=window.history.state)||void 0===t?void 0:t.marpBespokeSyncKey)||Math.random().toString(36).slice(2),r=`bespoke-marp-sync-${n}`;var i;i={marpBespokeSyncKey:n},m({},{setter:(e,...t)=>o({...e,...i},...t)});const a=()=>{const e=p(r);return e?JSON.parse(e):Object.create(null)},s=e=>{const t=a(),n={...t,...e(t)};return v(r,JSON.stringify(n)),n},l=()=>{window.removeEventListener("pageshow",l),s((e=>({reference:(e.reference||0)+1})))};return e=>{l(),Object.defineProperty(e,"syncKey",{value:n,enumerable:!0});let t=!0;setTimeout((()=>{e.on("fragment",(e=>{t&&s((()=>({index:e.index,fragmentIndex:e.fragmentIndex})))}))}),0),window.addEventListener("storage",(n=>{if(n.key===r&&n.oldValue&&n.newValue){const r=JSON.parse(n.oldValue),o=JSON.parse(n.newValue);if(r.index!==o.index||r.fragmentIndex!==o.fragmentIndex)try{t=!1,e.slide(o.index,{fragment:o.fragmentIndex,forSync:!0})}finally{t=!0}}}));const o=()=>{const{reference:e}=a();void 0===e||e<=1?h(r):s((()=>({reference:e-1})))};window.addEventListener("pagehide",(e=>{e.persisted&&window.addEventListener("pageshow",l),o()})),e.on("destroy",o)}},{PI:Q,abs:Z,sqrt:ee,atan2:te}=Math,ne={passive:!0},re=({slope:e=-.7,swipeThreshold:t=30}={})=>n=>{let r;const o=n.parent,i=e=>{const t=o.getBoundingClientRect();return{x:e.pageX-(t.left+t.right)/2,y:e.pageY-(t.top+t.bottom)/2}};o.addEventListener("touchstart",(({touches:e})=>{r=1===e.length?i(e[0]):void 0}),ne),o.addEventListener("touchmove",(e=>{if(r)if(1===e.touches.length){e.preventDefault();const t=i(e.touches[0]),n=t.x-r.x,o=t.y-r.y;r.delta=ee(Z(n)**2+Z(o)**2),r.radian=te(n,o)}else r=void 0})),o.addEventListener("touchend",(o=>{if(r){if(r.delta&&r.delta>=t&&r.radian){const t=(r.radian-e+Q)%(2*Q)-Q;n[t<0?"next":"prev"](),o.stopPropagation()}r=void 0}}),ne)},oe=new Map;oe.clear(),oe.set("none",{backward:{both:void 0,incoming:void 0,outgoing:void 0},forward:{both:void 0,incoming:void 0,outgoing:void 0}});const ie={both:"",outgoing:"outgoing-",incoming:"incoming-"},ae={forward:"",backward:"-backward"},se=e=>`--marp-bespoke-transition-animation-${e}`,le=e=>`--marp-transition-${e}`,ce=se("name"),de=se("duration"),ue=e=>new Promise((t=>{const n={},r=document.createElement("div"),o=e=>{r.remove(),t(e)};r.addEventListener("animationstart",(()=>o(n))),Object.assign(r.style,{animationName:e,animationDuration:"1s",animationFillMode:"both",animationPlayState:"paused",position:"absolute",pointerEvents:"none"}),document.body.appendChild(r);const i=getComputedStyle(r).getPropertyValue(le("duration"));i&&(n.defaultDuration=i),((e,t)=>{requestAnimationFrame((()=>{e.style.animationPlayState="running",requestAnimationFrame((()=>t(void 0)))}))})(r,o)})),fe=async e=>oe.has(e)?oe.get(e):(e=>{const t={},n=[];for(const[r,o]of Object.entries(ie))for(const[i,a]of Object.entries(ae)){const s=`marp-${o}transition${a}-${e}`;n.push(ue(s).then((e=>{t[i]=t[i]||{},t[i][r]=e?{...e,name:s}:void 0})))}return Promise.all(n).then((()=>t))})(e).then((t=>(oe.set(e,t),t))),me=e=>Object.values(e).flatMap(Object.values).every((e=>!e)),ge=(e,{type:t,backward:n})=>{const r=e[n?"backward":"forward"],o=(()=>{const e=r[t],n=e=>({[ce]:e.name});if(e)return n(e);if(r.both){const e=n(r.both);return"incoming"===t&&(e[se("direction")]="reverse"),e}})();return!o&&n?ge(e,{type:t,backward:!1}):o||{[ce]:"__bespoke_marp_transition_no_animation__"}},pe=e=>{if(e)try{const t=JSON.parse(e);if((e=>{if("object"!=typeof e)return!1;const t=e;return"string"==typeof t.name&&(void 0===t.duration||"string"==typeof t.duration)})(t))return t}catch(e){}},ve="_tSId",he="_tA",ye="bespoke-marp-transition-warming-up",be=window.matchMedia("(prefers-reduced-motion: reduce)"),we="__bespoke_marp_transition_reduced_outgoing__",xe="__bespoke_marp_transition_reduced_incoming__",ke={forward:{both:void 0,incoming:{name:xe},outgoing:{name:we}},backward:{both:void 0,incoming:{name:xe},outgoing:{name:we}}},$e=e=>{if(!document.startViewTransition)return;const t=t=>(void 0!==t&&(e._tD=t),e._tD);let n;t(!1),((...e)=>{const t=[...new Set(e).values()];return Promise.all(t.map((e=>fe(e)))).then()})(...Array.from(document.querySelectorAll("section[data-transition], section[data-transition-back]")).flatMap((e=>[e.dataset.transition,e.dataset.transitionBack].flatMap((e=>{const t=pe(e);return[null==t?void 0:t.name,(null==t?void 0:t.builtinFallback)?`__builtin__${t.name}`:void 0]})).filter((e=>!!e))))).then((()=>{document.querySelectorAll("style").forEach((e=>{e.innerHTML=e.innerHTML.replace(/--marp-transition-duration:[^;}]*[;}]/g,(e=>e.slice(0,-1)+"!important"+e.slice(-1)))}))}));const r=(n,{back:r,cond:o})=>i=>{var a;const s=t();if(s)return!!i[he]||!("object"!=typeof s||(s.skipTransition(),!i.forSync));if(!o(i))return!0;const l=e.slides[e.slide()],c=()=>{var e;return null!==(e=i.back)&&void 0!==e?e:r},d="data-transition"+(c()?"-back":""),u=l.querySelector(`section[${d}]`);if(!u)return!0;const f=pe(null!==(a=u.getAttribute(d))&&void 0!==a?a:void 0);return!f||((async(e,{builtinFallback:t=!0}={})=>{let n=await fe(e);if(me(n)){if(!t)return;return n=await fe(`__builtin__${e}`),me(n)?void 0:n}return n})(f.name,{builtinFallback:f.builtinFallback}).then((e=>{if(!e){t(!0);try{n(i)}finally{t(!1)}return}let r=e;be.matches&&(console.warn("Use a constant animation to transition because preferring reduced motion by viewer has detected."),r=ke);const o=document.getElementById(ve);o&&o.remove();const a=document.createElement("style");a.id=ve,document.head.appendChild(a),((e,t)=>{const n=[`:root{${le("direction")}:${t.backward?-1:1};}`,":root:has(.bespoke-marp-inactive){cursor:none;}"],r=t=>{var n,o,i;const a=(null===(n=e[t].both)||void 0===n?void 0:n.defaultDuration)||(null===(o=e[t].outgoing)||void 0===o?void 0:o.defaultDuration)||(null===(i=e[t].incoming)||void 0===i?void 0:i.defaultDuration);return"forward"===t?a:a||r("forward")},o=t.duration||r(t.backward?"backward":"forward");void 0!==o&&n.push(`::view-transition-group(*){${de}:${o};}`);const i=e=>Object.entries(e).map((([e,t])=>`${e}:${t};`)).join("");return n.push(`::view-transition-old(root){${i(ge(e,{...t,type:"outgoing"}))}}`,`::view-transition-new(root){${i(ge(e,{...t,type:"incoming"}))}}`),n})(r,{backward:c(),duration:f.duration}).forEach((e=>{var t;return null===(t=a.sheet)||void 0===t?void 0:t.insertRule(e)}));const s=document.documentElement.classList;s.add(ye);let l=!1;const d=()=>{l||(n(i),l=!0,s.remove(ye))},u=()=>{t(!1),a.remove(),s.remove(ye)};try{t(!0);const e=document.startViewTransition(d);t(e),e.finished.finally(u)}catch(e){console.error(e),d(),u()}})),!1)};e.on("prev",r((t=>e.prev({...t,[he]:!0})),{back:!0,cond:e=>{var t;return e.index>0&&!((null===(t=e.fragment)||void 0===t||t)&&n.fragmentIndex>0)}})),e.on("next",r((t=>e.next({...t,[he]:!0})),{cond:t=>t.index+1<e.slides.length&&!(n.fragmentIndex+1<n.fragments.length)})),setTimeout((()=>{e.on("slide",r((t=>e.slide(t.index,{...t,[he]:!0})),{cond:t=>{const n=e.slide();return t.index!==n&&(t.back=t.index<n,!0)}}))}),0),e.on("fragment",(e=>{n=e}))};let Ee;const Le=()=>(void 0===Ee&&(Ee="wakeLock"in navigator&&navigator.wakeLock),Ee),Se=async()=>{const e=Le();if(e)try{return await e.request("screen")}catch(e){console.warn(e)}return null},Pe=async()=>{if(!Le())return;let e;const t=()=>{e&&"visible"===document.visibilityState&&Se()};for(const e of["visibilitychange","fullscreenchange"])document.addEventListener(e,t);return e=await Se(),e};((e=document.getElementById(":$p"))=>{(()=>{const e=f("view");r.dataset.bespokeView=e===a||e===i?e:""})();const t=(e=>{const t=f(e);return m({[e]:void 0}),t})("sync")||void 0;n.from(e,((...e)=>{const t=s.findIndex((e=>u()===e));return e.map((([e,n])=>e[t]&&n)).filter((e=>e))})([[1,1,0],G({key:t})],[[1,1,1],W(e)],[[1,1,0],_],[[1,1,1],b],[[1,0,0],S()],[[1,1,1],T],[[1,1,1],z({history:!1})],[[1,1,0],I()],[[1,1,0],E],[[1,0,0],J],[[1,1,0],re()],[[1,0,0],M()],[[1,0,0],$e],[[1,1,1],w],[[1,1,0],Pe]))})()}();</script></body></html>